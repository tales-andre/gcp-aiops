[
  {
    "error": "OOMKilled",
    "patterns": [
      "OOMKilled",
      "Out of memory",
      "Killed process",
      "memory cgroup out of memory",
      "signal: killed",
      "evicted: The node was low on resource: memory"
    ],
    "solution": "O problema **OOMKilled** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Limite de memória (`resources.limits.memory`) menor que o uso real do processo.\n- *Spikes* de alocação (cache, buffers, *JIT* ou *GC*) não refletidos em `requests`.\n- Vazamentos ou *memory bloat* (por exemplo: grandes *batches*, buffers não liberados).\n#### Ações imediatas\n- Verifique o motivo exato do OOM nos eventos: `kubectl describe pod <pod> -n <ns>` (campo *Last State* / *Reason*).\n- Confira reinícios: `kubectl get pod <pod> -n <ns> -o wide` e `kubectl logs <pod> -n <ns> --previous`.\n- Observe consumo: instale *metrics-server* e rode `kubectl top pod <pod> -n <ns>`.\n- Se JVM: adicione flags que respeitem cgroups (ex.: `-XX:+UseContainerSupport -XX:MaxRAMPercentage=75`);\n  se Node.js: ajuste `--max-old-space-size`; se Python: reduza *workers*/*batch size*.\n#### Correções\n- **Dimensione corretamente**: aumente `requests` para o pico de uso e `limits` com margem (10–30%).\n- **Otimize a aplicação**: reduza paralelismo, *batch size*, *buffers*; corrija vazamentos.\n- **Autoscaling**: considere *Vertical Pod Autoscaler* (VPA) e *HPA* baseado em memória onde aplicável.\n- **Probes**: evite que *liveness* mate o pod durante *warmup* — use `startupProbe` e tempos mais generosos.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "a94fe96f5394",
    "category": "Pod Runtime",
    "severity": "high",
    "explanation": "Descrição: 'OOMKilled' geralmente indica um problema na categoria Pod Runtime. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl top pod <pod> -n <ns>",
      "kubectl top node"
    ],
    "fix_steps": [
      "Ajuste `resources.requests/limits.memory` baseado no pico observado.",
      "Reduza *batch size*, paralelismo e *caches*; aplique flags de memória do runtime (JVM/Node/Python).",
      "Implemente `startupProbe` para proteger a inicialização e evite *liveness* prematura.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Ajuste requests/limits de CPU/Memória, comandos/args e dependências iniciais.",
      "Cheque volumes/paths/permissions exigidos pelo container."
    ],
    "tags": [
      "OOMKilled"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl top pod <pod> -n <ns>",
      "kubectl top node",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "CrashLoopBackOff",
    "patterns": [
      "CrashLoopBackOff",
      "Back-off restarting failed container",
      "back-off restarting failed container"
    ],
    "solution": "O problema **CrashLoopBackOff** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Falha no *entrypoint*/`command`, dependência externa indisponível, *config* ausente, ou *panic* da aplicação.\n- *Probes* agressivas derrubando o processo durante a inicialização.\n#### Ações imediatas\n- Veja o contêiner anterior: `kubectl logs <pod> -n <ns> --previous` (indica a causa de saída).\n- Descreva o pod e eventos: `kubectl describe pod <pod> -n <ns>` (erros de mount/env/args).\n#### Correções\n- Corrija env/args/arquivos requeridos; torne scripts executáveis (`chmod +x`).\n- Se devido a *readiness/liveness*, relaxe `initialDelaySeconds`, `periodSeconds`, `timeoutSeconds` e `failureThreshold`.\n- Aumente `terminationGracePeriodSeconds` se precisar finalizar com *graceful shutdown*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "f2c9ad1ce0a0",
    "category": "Pod Runtime",
    "severity": "high",
    "explanation": "Descrição: 'CrashLoopBackOff' geralmente indica um problema na categoria Pod Runtime. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Corrija `command`/`args`/`entrypoint`; torne scripts executáveis.",
      "Revise *probes* e aumente tempos/thresholds conforme necessidade.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Ajuste requests/limits de CPU/Memória, comandos/args e dependências iniciais.",
      "Cheque volumes/paths/permissions exigidos pelo container."
    ],
    "tags": [
      "CrashLoopBackOff"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "CreateContainerConfigError",
    "patterns": [
      "CreateContainerConfigError",
      "Error creating: config error",
      "configmap not found",
      "secret .* not found",
      "re:Error from server \\(NotFound\\): secrets? .* not found"
    ],
    "solution": "O problema **CreateContainerConfigError** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "894dad88277a",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'CreateContainerConfigError' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "CreateContainerConfigError"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "CreateContainerError",
    "patterns": [
      "CreateContainerError",
      "Error: failed to create containerd task",
      "re:failed to create container .*"
    ],
    "solution": "O problema **CreateContainerError** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "8c04fa061020",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'CreateContainerError' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "CreateContainerError"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "RunContainerError",
    "patterns": [
      "RunContainerError",
      "re:failed to start container .*",
      "re:OCI runtime create failed.*"
    ],
    "solution": "O problema **RunContainerError** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "23dbd026d811",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'RunContainerError' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "RunContainerError"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Error: failed to start container",
    "patterns": [
      "Error: failed to start container",
      "re:executable file not found in \\$PATH",
      "permission denied while trying to connect to the Docker daemon socket"
    ],
    "solution": "O problema **Error: failed to start container** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "10f0b94e6be9",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Error: failed to start container' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Error",
      "container",
      "failed",
      "start"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "ImagePullBackOff",
    "patterns": [
      "ImagePullBackOff",
      "back-off pulling image",
      "ErrImagePull"
    ],
    "solution": "O problema **ImagePullBackOff** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Falha no *entrypoint*/`command`, dependência externa indisponível, *config* ausente, ou *panic* da aplicação.\n- *Probes* agressivas derrubando o processo durante a inicialização.\n#### Ações imediatas\n- Veja o contêiner anterior: `kubectl logs <pod> -n <ns> --previous` (indica a causa de saída).\n- Descreva o pod e eventos: `kubectl describe pod <pod> -n <ns>` (erros de mount/env/args).\n#### Correções\n- Corrija env/args/arquivos requeridos; torne scripts executáveis (`chmod +x`).\n- Se devido a *readiness/liveness*, relaxe `initialDelaySeconds`, `periodSeconds`, `timeoutSeconds` e `failureThreshold`.\n- Aumente `terminationGracePeriodSeconds` se precisar finalizar com *graceful shutdown*.\n#### Causas comuns\n- Nome/tag inválidos, imagem inexistente, ou credenciais/egresso até o *registry* indisponíveis.\n#### Ações imediatas\n- Confirme *image* e *tag/digest* exatamente como publicadas.\n- Se privado: crie `Secret` tipo `docker-registry` e referencie em `imagePullSecrets`.\n- Teste no nó: `crictl pull <image>:<tag>` (ou `docker/podman`).\n#### Correções\n- Ajuste o nome totalmente qualificado (ex.: `gcr.io/proj/app:1.2.3` / `public.ecr.aws/...`).\n- Garanta permissões no *registry* e políticas de rede/egress liberadas.\n- Use `imagePullPolicy: IfNotPresent` (ou `Always` onde fizer sentido).\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "a977a4256291",
    "category": "Image/Registry",
    "severity": "medium",
    "explanation": "Descrição: 'ImagePullBackOff' geralmente indica um problema na categoria Image/Registry. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó"
    ],
    "fix_steps": [
      "Corrija `command`/`args`/`entrypoint`; torne scripts executáveis.",
      "Revise *probes* e aumente tempos/thresholds conforme necessidade.",
      "Corrija nome/tag da imagem e *imagePullSecrets*.",
      "Valide conectividade de rede ao *registry* (egresso/HTTP proxy).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Garanta imagePullSecrets corretos e acesso ao registry.",
      "Valide tag/digest e disponibilidade da imagem no registry."
    ],
    "tags": [
      "ImagePullBackOff"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "InvalidImageName",
    "patterns": [
      "InvalidImageName",
      "invalid reference format",
      "Error response from daemon: pull access denied for"
    ],
    "solution": "O problema **InvalidImageName** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Nome/tag inválidos, imagem inexistente, ou credenciais/egresso até o *registry* indisponíveis.\n#### Ações imediatas\n- Confirme *image* e *tag/digest* exatamente como publicadas.\n- Se privado: crie `Secret` tipo `docker-registry` e referencie em `imagePullSecrets`.\n- Teste no nó: `crictl pull <image>:<tag>` (ou `docker/podman`).\n#### Correções\n- Ajuste o nome totalmente qualificado (ex.: `gcr.io/proj/app:1.2.3` / `public.ecr.aws/...`).\n- Garanta permissões no *registry* e políticas de rede/egress liberadas.\n- Use `imagePullPolicy: IfNotPresent` (ou `Always` onde fizer sentido).\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "4fb602b04da9",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'InvalidImageName' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó"
    ],
    "fix_steps": [
      "Corrija nome/tag da imagem e *imagePullSecrets*.",
      "Valide conectividade de rede ao *registry* (egresso/HTTP proxy).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "InvalidImageName"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "ErrImageNeverPull",
    "patterns": [
      "ErrImageNeverPull",
      "re:image pull policy is Never.*"
    ],
    "solution": "O problema **ErrImageNeverPull** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Nome/tag inválidos, imagem inexistente, ou credenciais/egresso até o *registry* indisponíveis.\n#### Ações imediatas\n- Confirme *image* e *tag/digest* exatamente como publicadas.\n- Se privado: crie `Secret` tipo `docker-registry` e referencie em `imagePullSecrets`.\n- Teste no nó: `crictl pull <image>:<tag>` (ou `docker/podman`).\n#### Correções\n- Ajuste o nome totalmente qualificado (ex.: `gcr.io/proj/app:1.2.3` / `public.ecr.aws/...`).\n- Garanta permissões no *registry* e políticas de rede/egress liberadas.\n- Use `imagePullPolicy: IfNotPresent` (ou `Always` onde fizer sentido).\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "398a2cd08382",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'ErrImageNeverPull' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó"
    ],
    "fix_steps": [
      "Corrija nome/tag da imagem e *imagePullSecrets*.",
      "Valide conectividade de rede ao *registry* (egresso/HTTP proxy).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "ErrImageNeverPull"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Readiness probe failed",
    "patterns": [
      "Readiness probe failed",
      "re:readiness probe failed: .*"
    ],
    "solution": "O problema **Readiness probe failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Boas práticas de *probes*\n- **startupProbe** protege a fase de *warmup*; somente depois habilite *liveness*.\n- Use `httpGet`/`tcpSocket` válidos e portas corretas (`containerPort` ↔ `targetPort`).\n- Ajuste `timeoutSeconds` e *thresholds* para evitar falsos positivos sob carga.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "a91d813efea2",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Readiness probe failed' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija `httpGet.path`/`port` ou `tcpSocket`; alinhe `containerPort` e `targetPort`.",
      "Use `startupProbe` antes da *liveness* para apps lentas.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Readiness",
      "failed",
      "probe"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Liveness probe failed",
    "patterns": [
      "Liveness probe failed",
      "re:liveness probe failed: .*"
    ],
    "solution": "O problema **Liveness probe failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Boas práticas de *probes*\n- **startupProbe** protege a fase de *warmup*; somente depois habilite *liveness*.\n- Use `httpGet`/`tcpSocket` válidos e portas corretas (`containerPort` ↔ `targetPort`).\n- Ajuste `timeoutSeconds` e *thresholds* para evitar falsos positivos sob carga.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "f55ce32b87dd",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Liveness probe failed' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija `httpGet.path`/`port` ou `tcpSocket`; alinhe `containerPort` e `targetPort`.",
      "Use `startupProbe` antes da *liveness* para apps lentas.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Liveness",
      "failed",
      "probe"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Startup probe failed",
    "patterns": [
      "Startup probe failed"
    ],
    "solution": "O problema **Startup probe failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Boas práticas de *probes*\n- **startupProbe** protege a fase de *warmup*; somente depois habilite *liveness*.\n- Use `httpGet`/`tcpSocket` válidos e portas corretas (`containerPort` ↔ `targetPort`).\n- Ajuste `timeoutSeconds` e *thresholds* para evitar falsos positivos sob carga.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "0fb83b24d88f",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Startup probe failed' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija `httpGet.path`/`port` ou `tcpSocket`; alinhe `containerPort` e `targetPort`.",
      "Use `startupProbe` antes da *liveness* para apps lentas.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Startup",
      "failed",
      "probe"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "FailedScheduling",
    "patterns": [
      "FailedScheduling",
      "re:0/\\d+ nodes are available",
      "No nodes are available that match all of the predicates"
    ],
    "solution": "O problema **FailedScheduling** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Falta de recursos no cluster, *requests* superestimados, *taints* sem *tolerations*, *affinity/selector* incompatíveis.\n#### Correções\n- Reduza *requests/limits* para *right-sizing* ou **escale** o cluster.\n- Ajuste `nodeSelector`/`nodeAffinity` para rótulos realmente presentes; adicione *tolerations* quando houver *taints*.\n- Revise `topologySpreadConstraints` e *PodDisruptionBudget* que podem bloquear o agendamento.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "3931557aa68d",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'FailedScheduling' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reduza *requests* ou escale nós; habilite/ajuste *Cluster Autoscaler*.",
      "Ajuste `nodeSelector`/`affinity`/`tolerations` para casar com os nós disponíveis.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "FailedScheduling"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Insufficient cpu",
    "patterns": [
      "Insufficient cpu",
      "re:0/\\d+ nodes are available: .* Insufficient cpu"
    ],
    "solution": "O problema **Insufficient cpu** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Falta de recursos no cluster, *requests* superestimados, *taints* sem *tolerations*, *affinity/selector* incompatíveis.\n#### Correções\n- Reduza *requests/limits* para *right-sizing* ou **escale** o cluster.\n- Ajuste `nodeSelector`/`nodeAffinity` para rótulos realmente presentes; adicione *tolerations* quando houver *taints*.\n- Revise `topologySpreadConstraints` e *PodDisruptionBudget* que podem bloquear o agendamento.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "cb8536c1c96d",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Insufficient cpu' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reduza *requests* ou escale nós; habilite/ajuste *Cluster Autoscaler*.",
      "Ajuste `nodeSelector`/`affinity`/`tolerations` para casar com os nós disponíveis.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Insufficient",
      "cpu"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Insufficient memory",
    "patterns": [
      "Insufficient memory",
      "re:0/\\d+ nodes are available: .* Insufficient memory"
    ],
    "solution": "O problema **Insufficient memory** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Falta de recursos no cluster, *requests* superestimados, *taints* sem *tolerations*, *affinity/selector* incompatíveis.\n#### Correções\n- Reduza *requests/limits* para *right-sizing* ou **escale** o cluster.\n- Ajuste `nodeSelector`/`nodeAffinity` para rótulos realmente presentes; adicione *tolerations* quando houver *taints*.\n- Revise `topologySpreadConstraints` e *PodDisruptionBudget* que podem bloquear o agendamento.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "4d2ae6cf3111",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Insufficient memory' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reduza *requests* ou escale nós; habilite/ajuste *Cluster Autoscaler*.",
      "Ajuste `nodeSelector`/`affinity`/`tolerations` para casar com os nós disponíveis.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Insufficient",
      "memory"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Node selector mismatch",
    "patterns": [
      "didn't match node selector",
      "re:node\\(s\\) didn't match node selector"
    ],
    "solution": "O problema **Node selector mismatch** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "9c7ce6b95570",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'Node selector mismatch' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Node",
      "mismatch",
      "selector"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Taint requires toleration",
    "patterns": [
      "NoSchedule",
      "re:node\\(s\\) had taint .* that the pod didn't tolerate"
    ],
    "solution": "O problema **Taint requires toleration** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "362cd34848a4",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'Taint requires toleration' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Taint",
      "requires",
      "toleration"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Volume node affinity conflict",
    "patterns": [
      "volume node affinity conflict",
      "re:node\\(s\\) had volume node affinity conflict"
    ],
    "solution": "O problema **Volume node affinity conflict** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "9b20daf5f5d1",
    "category": "Storage/CSI",
    "severity": "medium",
    "explanation": "Descrição: 'Volume node affinity conflict' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "Volume",
      "affinity",
      "conflict",
      "node"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Unbound PVC blocks scheduling",
    "patterns": [
      "pod has unbound immediate PersistentVolumeClaims"
    ],
    "solution": "O problema **Unbound PVC blocks scheduling** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Falta de recursos no cluster, *requests* superestimados, *taints* sem *tolerations*, *affinity/selector* incompatíveis.\n#### Correções\n- Reduza *requests/limits* para *right-sizing* ou **escale** o cluster.\n- Ajuste `nodeSelector`/`nodeAffinity` para rótulos realmente presentes; adicione *tolerations* quando houver *taints*.\n- Revise `topologySpreadConstraints` e *PodDisruptionBudget* que podem bloquear o agendamento.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "6369e517e8e7",
    "category": "Storage/CSI",
    "severity": "medium",
    "explanation": "Descrição: 'Unbound PVC blocks scheduling' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Reduza *requests* ou escale nós; habilite/ajuste *Cluster Autoscaler*.",
      "Ajuste `nodeSelector`/`affinity`/`tolerations` para casar com os nós disponíveis.",
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "PVC",
      "Unbound",
      "blocks",
      "scheduling"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "PVC not bound",
    "patterns": [
      "persistentvolumeclaim .* is not bound",
      "re:persistentvolumeclaim \\\".*\\\" is not bound"
    ],
    "solution": "O problema **PVC not bound** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "df80c9d119ca",
    "category": "Storage/CSI",
    "severity": "medium",
    "explanation": "Descrição: 'PVC not bound' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "PVC",
      "bound",
      "not"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "WaitForFirstConsumer",
    "patterns": [
      "waiting for first consumer to be created before binding"
    ],
    "solution": "O problema **WaitForFirstConsumer** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "c0de2ba7c117",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'WaitForFirstConsumer' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "WaitForFirstConsumer"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "No PVs and no StorageClass",
    "patterns": [
      "no persistent volumes available for this claim and no storage class is set"
    ],
    "solution": "O problema **No PVs and no StorageClass** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "9a89aca34d67",
    "category": "Storage/CSI",
    "severity": "medium",
    "explanation": "Descrição: 'No PVs and no StorageClass' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "PVs",
      "StorageClass",
      "and"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "MountVolume.SetUp failed",
    "patterns": [
      "MountVolume.SetUp failed for volume",
      "re:MountVolume.SetUp failed for volume \\\".*\\\": .*"
    ],
    "solution": "O problema **MountVolume.SetUp failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "9498b935ad92",
    "category": "Storage/CSI",
    "severity": "high",
    "explanation": "Descrição: 'MountVolume.SetUp failed' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "MountVolume",
      "SetUp",
      "failed"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "MountVolume.MountDevice failed",
    "patterns": [
      "MountVolume.MountDevice failed"
    ],
    "solution": "O problema **MountVolume.MountDevice failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "ac19d7fad4d8",
    "category": "Storage/CSI",
    "severity": "high",
    "explanation": "Descrição: 'MountVolume.MountDevice failed' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "MountDevice",
      "MountVolume",
      "failed"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Multi-Attach error",
    "patterns": [
      "Multi-Attach error for volume"
    ],
    "solution": "O problema **Multi-Attach error** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "f1b17c538113",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Multi-Attach error' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Multi-Attach",
      "error"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Read-only file system",
    "patterns": [
      "Read-only file system",
      "EROFS"
    ],
    "solution": "O problema **Read-only file system** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Sistema de arquivos e permissões\n- **Read-only**: monte com `readOnly: false` onde precisa escrever.\n- Defina `securityContext`: `runAsUser`, `runAsGroup`, `fsGroup` para ownership correto.\n- Corrija `no such file` verificando `workingDir`, caminho do *entrypoint* e *scripts* executáveis (`chmod +x`).\n- **operation not permitted**: evite `privileged`; adicione apenas *capabilities* necessárias (ex.: `NET_ADMIN`).\n- Em ambientes com SELinux/AppArmor, ajuste *labels* ou *profiles* adequados.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "195725140c44",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Read-only file system' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Monte com `readOnly: false` onde escreve e ajuste `fsGroup`/`runAsUser`.",
      "Corrija caminhos/`workingDir` e permissões de execução.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Read-only",
      "file",
      "system"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "permission denied",
    "patterns": [
      "permission denied",
      "EPERM",
      "EACCES"
    ],
    "solution": "O problema **permission denied** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Sistema de arquivos e permissões\n- **Read-only**: monte com `readOnly: false` onde precisa escrever.\n- Defina `securityContext`: `runAsUser`, `runAsGroup`, `fsGroup` para ownership correto.\n- Corrija `no such file` verificando `workingDir`, caminho do *entrypoint* e *scripts* executáveis (`chmod +x`).\n- **operation not permitted**: evite `privileged`; adicione apenas *capabilities* necessárias (ex.: `NET_ADMIN`).\n- Em ambientes com SELinux/AppArmor, ajuste *labels* ou *profiles* adequados.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "ddc4c22fba61",
    "category": "RBAC/Auth",
    "severity": "high",
    "explanation": "Descrição: 'permission denied' geralmente indica um problema na categoria RBAC/Auth. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Monte com `readOnly: false` onde escreve e ajuste `fsGroup`/`runAsUser`.",
      "Corrija caminhos/`workingDir` e permissões de execução.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "denied",
      "permission"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "no such file or directory",
    "patterns": [
      "no such file or directory",
      "ENOENT"
    ],
    "solution": "O problema **no such file or directory** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Sistema de arquivos e permissões\n- **Read-only**: monte com `readOnly: false` onde precisa escrever.\n- Defina `securityContext`: `runAsUser`, `runAsGroup`, `fsGroup` para ownership correto.\n- Corrija `no such file` verificando `workingDir`, caminho do *entrypoint* e *scripts* executáveis (`chmod +x`).\n- **operation not permitted**: evite `privileged`; adicione apenas *capabilities* necessárias (ex.: `NET_ADMIN`).\n- Em ambientes com SELinux/AppArmor, ajuste *labels* ou *profiles* adequados.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "7b76d8429c6f",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'no such file or directory' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Monte com `readOnly: false` onde escreve e ajuste `fsGroup`/`runAsUser`.",
      "Corrija caminhos/`workingDir` e permissões de execução.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "directory",
      "file",
      "such"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "operation not permitted",
    "patterns": [
      "operation not permitted"
    ],
    "solution": "O problema **operation not permitted** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Sistema de arquivos e permissões\n- **Read-only**: monte com `readOnly: false` onde precisa escrever.\n- Defina `securityContext`: `runAsUser`, `runAsGroup`, `fsGroup` para ownership correto.\n- Corrija `no such file` verificando `workingDir`, caminho do *entrypoint* e *scripts* executáveis (`chmod +x`).\n- **operation not permitted**: evite `privileged`; adicione apenas *capabilities* necessárias (ex.: `NET_ADMIN`).\n- Em ambientes com SELinux/AppArmor, ajuste *labels* ou *profiles* adequados.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "40d88935fa4d",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'operation not permitted' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Monte com `readOnly: false` onde escreve e ajuste `fsGroup`/`runAsUser`.",
      "Corrija caminhos/`workingDir` e permissões de execução.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "not",
      "operation",
      "permitted"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "No endpoints for service",
    "patterns": [
      "re:no endpoints available for service\\s+\"?[\\w\\-\\.]+\"?"
    ],
    "solution": "O problema **No endpoints for service** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Conectividade de *Services*\n- Verifique `Service` ↔ *pods* via `selector`/labels; inspecione `endpoints`/`endpointslices`.\n- Valide `targetPort` e a aplicação escutando (`netstat -tlnp` dentro do contêiner).\n- Revise *NetworkPolicies* e *egress* do *namespace*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "583636f33574",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'No endpoints for service' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija `selector`/labels do Service e confirme *endpoints*.",
      "Valide `targetPort` e que o app escuta na porta correta.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "endpoints",
      "for",
      "service"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "connection refused",
    "patterns": [
      "connection refused",
      "ECONNREFUSED"
    ],
    "solution": "O problema **connection refused** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Conectividade de *Services*\n- Verifique `Service` ↔ *pods* via `selector`/labels; inspecione `endpoints`/`endpointslices`.\n- Valide `targetPort` e a aplicação escutando (`netstat -tlnp` dentro do contêiner).\n- Revise *NetworkPolicies* e *egress* do *namespace*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "72e5bd92956a",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'connection refused' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija `selector`/labels do Service e confirme *endpoints*.",
      "Valide `targetPort` e que o app escuta na porta correta.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "connection",
      "refused"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "i/o timeout",
    "patterns": [
      "i/o timeout",
      "ETIMEDOUT",
      "context deadline exceeded"
    ],
    "solution": "O problema **i/o timeout** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Conectividade de *Services*\n- Verifique `Service` ↔ *pods* via `selector`/labels; inspecione `endpoints`/`endpointslices`.\n- Valide `targetPort` e a aplicação escutando (`netstat -tlnp` dentro do contêiner).\n- Revise *NetworkPolicies* e *egress* do *namespace*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "cbd00ea35c03",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'i/o timeout' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija `selector`/labels do Service e confirme *endpoints*.",
      "Valide `targetPort` e que o app escuta na porta correta.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "i/o",
      "timeout"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "DNS no such host",
    "patterns": [
      "re:lookup .* on .*: no such host",
      "no such host"
    ],
    "solution": "O problema **DNS no such host** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### DNS/CoreDNS\n- Teste dentro do *pod*: `nslookup`/`dig` para o FQDN; cheque `/etc/resolv.conf`.\n- Reinicie `coredns` se travado; confirme *upstream* acessível e políticas de rede liberando DNS.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "9405cc52a77c",
    "category": "Networking/DNS",
    "severity": "medium",
    "explanation": "Descrição: Falhas de resolução DNS (ex.: 'no such host', 'NXDOMAIN') indicam que o nome não pode ser resolvido pelo CoreDNS ou pelo DNS externo.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl -n kube-system logs deploy/coredns --tail=200",
      "kubectl exec -it <pod> -n <ns> -- nslookup <host>"
    ],
    "fix_steps": [
      "Corrija o FQDN/hostname; confira `coredns` e DNS *upstream*.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Corrija o FQDN/hostname e verifique se há registros A/CNAME/TXT válidos.",
      "Se for serviço K8s, confirme Service/Endpoints e o sufixo .svc.cluster.local.",
      "Cheque políticas de rede/egress e o acesso ao DNS upstream."
    ],
    "tags": [
      "DNS",
      "host",
      "such"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl -n kube-system logs deploy/coredns --tail=200",
      "kubectl exec -it <pod> -n <ns> -- nslookup <host>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "ClusterIP unreachable",
    "patterns": [
      "ClusterIP service unreachable",
      "KUBE-SVC iptables rules missing",
      "re:Cilium.*service.*unreachable"
    ],
    "solution": "O problema **ClusterIP unreachable** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "bd284589a485",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'ClusterIP unreachable' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "ClusterIP",
      "unreachable"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "CNI plugin not ready",
    "patterns": [
      "NetworkPlugin cni failed to set up pod",
      "cni config uninitialized",
      "CNI plugin not initialized"
    ],
    "solution": "O problema **CNI plugin not ready** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### CNI/Runtime\n- *Pod sandbox* falhas normalmente indicam CNI ou container runtime com problemas.\n- Confira *daemonset* do CNI (Calico/Cilium/Weave) e logs do `kubelet`/`containerd`.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "8615797bc1cd",
    "category": "CNI/Networking",
    "severity": "medium",
    "explanation": "Descrição: 'CNI plugin not ready' geralmente indica um problema na categoria CNI/Networking. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "CNI",
      "not",
      "plugin",
      "ready"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Failed to create pod sandbox",
    "patterns": [
      "failed to create pod sandbox: rpc error",
      "re:failed to setup network for sandbox.*"
    ],
    "solution": "O problema **Failed to create pod sandbox** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### CNI/Runtime\n- *Pod sandbox* falhas normalmente indicam CNI ou container runtime com problemas.\n- Confira *daemonset* do CNI (Calico/Cilium/Weave) e logs do `kubelet`/`containerd`.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "e52135fd80e9",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Failed to create pod sandbox' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Failed",
      "create",
      "pod",
      "sandbox"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "port is already allocated",
    "patterns": [
      "port is already allocated",
      "Bind for 0.0.0.0:* failed"
    ],
    "solution": "O problema **port is already allocated** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Porta já alocada\n- Evite conflitos de `hostPort`; remova ou altere a porta.\n- Em NodePort, use portas distintas e libere firewall conforme necessário.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "0e8014222be5",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'port is already allocated' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "allocated",
      "already",
      "port"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Ingress default backend 404",
    "patterns": [
      "default backend - 404",
      "404 Not Found from Ingress"
    ],
    "solution": "O problema **Ingress default backend 404** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Ingress/Certificados\n- *404 default backend*: `serviceName`/`servicePort` e `pathType` incorretos são comuns.\n- **TLS**: crie `Secret` tipo `kubernetes.io/tls` com `tls.crt`/`tls.key`; cheque *CN/SAN* corretos.\n- Para `x509`/`handshake` erros, valide cadeia de certificados e *trust store* do upstream.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "b27e26fe235b",
    "category": "Ingress",
    "severity": "medium",
    "explanation": "Descrição: 'Ingress default backend 404' geralmente indica um problema na categoria Ingress. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Ajuste `path`, `pathType` e backends; corrija o `Secret` TLS (tipo `kubernetes.io/tls`).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "404",
      "Ingress",
      "backend",
      "default"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Ingress TLS secret not found",
    "patterns": [
      "re:secret \\\".*\\\" not found",
      "tls: private key does not match public certificate"
    ],
    "solution": "O problema **Ingress TLS secret not found** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Ingress/Certificados\n- *404 default backend*: `serviceName`/`servicePort` e `pathType` incorretos são comuns.\n- **TLS**: crie `Secret` tipo `kubernetes.io/tls` com `tls.crt`/`tls.key`; cheque *CN/SAN* corretos.\n- Para `x509`/`handshake` erros, valide cadeia de certificados e *trust store* do upstream.\n#### AWS (EKS/IRSA/Storage)\n- **IRSA/STS**: confira *OIDC provider* e *trust policy* do *role*; anote o SA com `eks.amazonaws.com/role-arn`.\n- **EBS/EFS**: políticas IAM para `AttachVolume`, `Describe*` e permissões do driver CSI.\n- **S3/KMS**: `s3:PutObject/GetObject` e `kms:Decrypt/Encrypt` conforme necessidade; revise *bucket policy* e *key policy*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "e9bd2aba6137",
    "category": "Ingress",
    "severity": "medium",
    "explanation": "Descrição: 'Ingress TLS secret not found' geralmente indica um problema na categoria Ingress. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Ajuste `path`, `pathType` e backends; corrija o `Secret` TLS (tipo `kubernetes.io/tls`).",
      "Revise *trust policy* do IAM Role (IRSA), políticas do driver CSI e permissões S3/KMS.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Ingress",
      "TLS",
      "found",
      "not",
      "secret"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Ingress upstream connect error",
    "patterns": [
      "upstream connect error or disconnect/reset before headers",
      "re:upstream .* connection failure"
    ],
    "solution": "O problema **Ingress upstream connect error** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Ingress/Certificados\n- *404 default backend*: `serviceName`/`servicePort` e `pathType` incorretos são comuns.\n- **TLS**: crie `Secret` tipo `kubernetes.io/tls` com `tls.crt`/`tls.key`; cheque *CN/SAN* corretos.\n- Para `x509`/`handshake` erros, valide cadeia de certificados e *trust store* do upstream.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "fbf641647c92",
    "category": "Ingress",
    "severity": "high",
    "explanation": "Descrição: 'Ingress upstream connect error' geralmente indica um problema na categoria Ingress. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Ajuste `path`, `pathType` e backends; corrija o `Secret` TLS (tipo `kubernetes.io/tls`).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Ingress",
      "connect",
      "error",
      "upstream"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "x509 unknown authority",
    "patterns": [
      "x509: certificate signed by unknown authority"
    ],
    "solution": "O problema **x509 unknown authority** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Ingress/Certificados\n- *404 default backend*: `serviceName`/`servicePort` e `pathType` incorretos são comuns.\n- **TLS**: crie `Secret` tipo `kubernetes.io/tls` com `tls.crt`/`tls.key`; cheque *CN/SAN* corretos.\n- Para `x509`/`handshake` erros, valide cadeia de certificados e *trust store* do upstream.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "b5fdeef032d5",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'x509 unknown authority' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Ajuste `path`, `pathType` e backends; corrija o `Secret` TLS (tipo `kubernetes.io/tls`).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "authority",
      "unknown",
      "x509"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "x509 expired or not yet valid",
    "patterns": [
      "x509: certificate has expired or is not yet valid"
    ],
    "solution": "O problema **x509 expired or not yet valid** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Ingress/Certificados\n- *404 default backend*: `serviceName`/`servicePort` e `pathType` incorretos são comuns.\n- **TLS**: crie `Secret` tipo `kubernetes.io/tls` com `tls.crt`/`tls.key`; cheque *CN/SAN* corretos.\n- Para `x509`/`handshake` erros, valide cadeia de certificados e *trust store* do upstream.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "0d008640fb63",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'x509 expired or not yet valid' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Ajuste `path`, `pathType` e backends; corrija o `Secret` TLS (tipo `kubernetes.io/tls`).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "expired",
      "not",
      "valid",
      "x509",
      "yet"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "TLS handshake error",
    "patterns": [
      "TLS handshake error",
      "remote error: tls: bad certificate"
    ],
    "solution": "O problema **TLS handshake error** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Ingress/Certificados\n- *404 default backend*: `serviceName`/`servicePort` e `pathType` incorretos são comuns.\n- **TLS**: crie `Secret` tipo `kubernetes.io/tls` com `tls.crt`/`tls.key`; cheque *CN/SAN* corretos.\n- Para `x509`/`handshake` erros, valide cadeia de certificados e *trust store* do upstream.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "42f824ec3705",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'TLS handshake error' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Ajuste `path`, `pathType` e backends; corrija o `Secret` TLS (tipo `kubernetes.io/tls`).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "TLS",
      "error",
      "handshake"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Forbidden list resource",
    "patterns": [
      "Forbidden: cannot list resource",
      "re:forbidden: User .* cannot list resource"
    ],
    "solution": "O problema **Forbidden list resource** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### RBAC/Autorização\n- Teste permissões: `kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>`.\n- Crie/ajuste `Role`/`ClusterRole` + `RoleBinding`/`ClusterRoleBinding`; garanta `serviceAccountName` correto no *pod*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "94cc209e1c2b",
    "category": "RBAC/Auth",
    "severity": "high",
    "explanation": "Descrição: 'Forbidden list resource' geralmente indica um problema na categoria RBAC/Auth. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A"
    ],
    "fix_steps": [
      "Crie/ajuste `Role`/`ClusterRole` e *bindings*; valide com `kubectl auth can-i`.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Forbidden",
      "list",
      "resource"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "SA cannot get resource",
    "patterns": [
      "re:User \\\"system:serviceaccount:.*\\\" cannot get resource"
    ],
    "solution": "O problema **SA cannot get resource** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### RBAC/Autorização\n- Teste permissões: `kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>`.\n- Crie/ajuste `Role`/`ClusterRole` + `RoleBinding`/`ClusterRoleBinding`; garanta `serviceAccountName` correto no *pod*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "a0fccb6cfeaf",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'SA cannot get resource' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A"
    ],
    "fix_steps": [
      "Crie/ajuste `Role`/`ClusterRole` e *bindings*; valide com `kubectl auth can-i`.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "cannot",
      "get",
      "resource"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "ServiceAccount not found",
    "patterns": [
      "serviceaccounts \\\".*\\\" not found"
    ],
    "solution": "O problema **ServiceAccount not found** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### RBAC/Autorização\n- Teste permissões: `kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>`.\n- Crie/ajuste `Role`/`ClusterRole` + `RoleBinding`/`ClusterRoleBinding`; garanta `serviceAccountName` correto no *pod*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "7477af68ffc8",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'ServiceAccount not found' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A"
    ],
    "fix_steps": [
      "Crie/ajuste `Role`/`ClusterRole` e *bindings*; valide com `kubectl auth can-i`.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "ServiceAccount",
      "found",
      "not"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Unauthorized",
    "patterns": [
      "Unauthorized",
      "re:the server responded with the status code 401"
    ],
    "solution": "O problema **Unauthorized** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### RBAC/Autorização\n- Teste permissões: `kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>`.\n- Crie/ajuste `Role`/`ClusterRole` + `RoleBinding`/`ClusterRoleBinding`; garanta `serviceAccountName` correto no *pod*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "b8b57bf10c71",
    "category": "RBAC/Auth",
    "severity": "medium",
    "explanation": "Descrição: 'Unauthorized' geralmente indica um problema na categoria RBAC/Auth. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A"
    ],
    "fix_steps": [
      "Crie/ajuste `Role`/`ClusterRole` e *bindings*; valide com `kubectl auth can-i`.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Unauthorized"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "NodeNotReady",
    "patterns": [
      "NodeNotReady",
      "node is not ready"
    ],
    "solution": "O problema **NodeNotReady** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Saúde do nó\n- `NodeNotReady`/`*Pressure`: verifique `kubelet`, uso de disco/FS, inodes e *allocatable resources*.\n- Habilite *eviction thresholds* apropriados e *requests* realistas para evitar *evictions*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "a8e937b1f431",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'NodeNotReady' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>"
    ],
    "fix_steps": [
      "Libere recursos (disco/memória), reponha nós ruins e ajuste *eviction thresholds*.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "NodeNotReady"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Node MemoryPressure",
    "patterns": [
      "NodeHasInsufficientMemory",
      "Node has condition: MemoryPressure"
    ],
    "solution": "O problema **Node MemoryPressure** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Saúde do nó\n- `NodeNotReady`/`*Pressure`: verifique `kubelet`, uso de disco/FS, inodes e *allocatable resources*.\n- Habilite *eviction thresholds* apropriados e *requests* realistas para evitar *evictions*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "1fa64b630ed6",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'Node MemoryPressure' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>"
    ],
    "fix_steps": [
      "Libere recursos (disco/memória), reponha nós ruins e ajuste *eviction thresholds*.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "MemoryPressure",
      "Node"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Node DiskPressure",
    "patterns": [
      "NodeHasDiskPressure",
      "Node has condition: DiskPressure"
    ],
    "solution": "O problema **Node DiskPressure** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Saúde do nó\n- `NodeNotReady`/`*Pressure`: verifique `kubelet`, uso de disco/FS, inodes e *allocatable resources*.\n- Habilite *eviction thresholds* apropriados e *requests* realistas para evitar *evictions*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "1cc1f51e7c8d",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'Node DiskPressure' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>"
    ],
    "fix_steps": [
      "Libere recursos (disco/memória), reponha nós ruins e ajuste *eviction thresholds*.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "DiskPressure",
      "Node"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Kubelet ContainerManager failure",
    "patterns": [
      "kubelet: failed to start ContainerManager",
      "cgroup driver mismatch"
    ],
    "solution": "O problema **Kubelet ContainerManager failure** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "f1dc65af2426",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'Kubelet ContainerManager failure' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "ContainerManager",
      "Kubelet",
      "failure"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "failed to get metrics for resource",
    "patterns": [
      "failed to get metrics for resource",
      "no metrics returned from resource metrics API"
    ],
    "solution": "O problema **failed to get metrics for resource** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "1a4ad7eb2da1",
    "category": "Observability",
    "severity": "high",
    "explanation": "Descrição: 'failed to get metrics for resource' geralmente indica um problema na categoria Observability. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "failed",
      "for",
      "get",
      "metrics",
      "resource"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "HPA unable to compute replicas",
    "patterns": [
      "HPA was unable to compute the replica count"
    ],
    "solution": "O problema **HPA unable to compute replicas** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "8a3fbe30f082",
    "category": "Observability",
    "severity": "medium",
    "explanation": "Descrição: 'HPA unable to compute replicas' geralmente indica um problema na categoria Observability. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "HPA",
      "compute",
      "replicas",
      "unable"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "ClusterAutoscaler not provisioning nodes",
    "patterns": [
      "NoNodeGroup",
      "NotTriggerScaleUp",
      "max node group size reached"
    ],
    "solution": "O problema **ClusterAutoscaler not provisioning nodes** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "95a10f3a5731",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'ClusterAutoscaler not provisioning nodes' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "ClusterAutoscaler",
      "nodes",
      "not",
      "provisioning"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Helm immutable field",
    "patterns": [
      "UPGRADE FAILED: cannot patch .* Invalid value: field is immutable"
    ],
    "solution": "O problema **Helm immutable field** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "7c3fc263b2cc",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Helm immutable field' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Helm",
      "field",
      "immutable"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Helm resource already exists",
    "patterns": [
      "INSTALLATION FAILED: rendered manifests contain a resource that already exists"
    ],
    "solution": "O problema **Helm resource already exists** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### AWS (EKS/IRSA/Storage)\n- **IRSA/STS**: confira *OIDC provider* e *trust policy* do *role*; anote o SA com `eks.amazonaws.com/role-arn`.\n- **EBS/EFS**: políticas IAM para `AttachVolume`, `Describe*` e permissões do driver CSI.\n- **S3/KMS**: `s3:PutObject/GetObject` e `kms:Decrypt/Encrypt` conforme necessidade; revise *bucket policy* e *key policy*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "859d753e419d",
    "category": "AWS/EKS",
    "severity": "medium",
    "explanation": "Descrição: 'Helm resource already exists' geralmente indica um problema na categoria AWS/EKS. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Revise *trust policy* do IAM Role (IRSA), políticas do driver CSI e permissões S3/KMS.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Habilite OIDC do cluster (IRSA) e vincule a policy correta à ServiceAccount.",
      "Ajuste permissões IAM com base na ação negada (CloudTrail)."
    ],
    "tags": [
      "Helm",
      "already",
      "exists",
      "resource"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "aws_permissions": [
      "ec2:Describe*",
      "ecr:GetAuthorizationToken",
      "elasticloadbalancing:*",
      "logs:*"
    ],
    "references": []
  },
  {
    "error": "helm rollback failed",
    "patterns": [
      "Error: rollback.* failed",
      "no deployed releases"
    ],
    "solution": "O problema **helm rollback failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "dbe4c6bc903d",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'helm rollback failed' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "failed",
      "helm",
      "rollback"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Prometheus scrape timeout",
    "patterns": [
      "prometheus scrape failed: context deadline exceeded",
      "Error scraping target"
    ],
    "solution": "O problema **Prometheus scrape timeout** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Conectividade de *Services*\n- Verifique `Service` ↔ *pods* via `selector`/labels; inspecione `endpoints`/`endpointslices`.\n- Valide `targetPort` e a aplicação escutando (`netstat -tlnp` dentro do contêiner).\n- Revise *NetworkPolicies* e *egress* do *namespace*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "20171f9201e9",
    "category": "Observability",
    "severity": "high",
    "explanation": "Descrição: 'Prometheus scrape timeout' geralmente indica um problema na categoria Observability. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija `selector`/labels do Service e confirme *endpoints*.",
      "Valide `targetPort` e que o app escuta na porta correta.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Prometheus",
      "scrape",
      "timeout"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Prometheus config reload error",
    "patterns": [
      "Error reloading config",
      "re:couldn't load configuration .*"
    ],
    "solution": "O problema **Prometheus config reload error** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "8dad64bdc560",
    "category": "Observability",
    "severity": "high",
    "explanation": "Descrição: 'Prometheus config reload error' geralmente indica um problema na categoria Observability. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Prometheus",
      "config",
      "error",
      "reload"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Grafana datasource not working",
    "patterns": [
      "Datasource is not working",
      "Invalid response code from datasource"
    ],
    "solution": "O problema **Grafana datasource not working** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "87d7d79b65a1",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Grafana datasource not working' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Grafana",
      "datasource",
      "not",
      "working"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Fluentd permission denied",
    "patterns": [
      "Fluentd permission denied",
      "re:tail .* permission denied"
    ],
    "solution": "O problema **Fluentd permission denied** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Sistema de arquivos e permissões\n- **Read-only**: monte com `readOnly: false` onde precisa escrever.\n- Defina `securityContext`: `runAsUser`, `runAsGroup`, `fsGroup` para ownership correto.\n- Corrija `no such file` verificando `workingDir`, caminho do *entrypoint* e *scripts* executáveis (`chmod +x`).\n- **operation not permitted**: evite `privileged`; adicione apenas *capabilities* necessárias (ex.: `NET_ADMIN`).\n- Em ambientes com SELinux/AppArmor, ajuste *labels* ou *profiles* adequados.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "6d09d354dca4",
    "category": "RBAC/Auth",
    "severity": "high",
    "explanation": "Descrição: 'Fluentd permission denied' geralmente indica um problema na categoria RBAC/Auth. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Monte com `readOnly: false` onde escreve e ajuste `fsGroup`/`runAsUser`.",
      "Corrija caminhos/`workingDir` e permissões de execução.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Fluentd",
      "denied",
      "permission"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "No space left on device",
    "patterns": [
      "No space left on device",
      "ENOSPC"
    ],
    "solution": "O problema **No space left on device** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "2bac2ba16514",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'No space left on device' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "device",
      "left",
      "space"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Failed to connect to Elasticsearch",
    "patterns": [
      "Failed to connect to Elasticsearch",
      "Connection refused.*elasticsearch"
    ],
    "solution": "O problema **Failed to connect to Elasticsearch** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "a3f6e8fab81b",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Failed to connect to Elasticsearch' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Elasticsearch",
      "Failed",
      "connect"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "kubeadm init preflight failed",
    "patterns": [
      "kubeadm init fails: preflight checks failed",
      "re:\\[ERROR SystemVerification\\]"
    ],
    "solution": "O problema **kubeadm init preflight failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "76ade20c82cb",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'kubeadm init preflight failed' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "failed",
      "init",
      "kubeadm",
      "preflight"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "kubeadm upgrade apply fails",
    "patterns": [
      "kubeadm upgrade apply fails",
      "re:errors during upgrade apply"
    ],
    "solution": "O problema **kubeadm upgrade apply fails** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "00214f1e9840",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'kubeadm upgrade apply fails' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "apply",
      "fails",
      "kubeadm",
      "upgrade"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "kubectl localhost:8080 refused",
    "patterns": [
      "the connection to the server localhost:8080 was refused",
      "re:You must be logged in to the server"
    ],
    "solution": "O problema **kubectl localhost:8080 refused** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "fd01796839ac",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'kubectl localhost:8080 refused' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "8080",
      "kubectl",
      "localhost",
      "refused"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "etcd request timed out",
    "patterns": [
      "etcdserver: request timed out"
    ],
    "solution": "O problema **etcd request timed out** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "909057db4091",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'etcd request timed out' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "etcd",
      "out",
      "request",
      "timed"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "etcd database space exceeded",
    "patterns": [
      "etcdserver: mvcc: database space exceeded"
    ],
    "solution": "O problema **etcd database space exceeded** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "ca623c4d60ce",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'etcd database space exceeded' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "database",
      "etcd",
      "exceeded",
      "space"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "High API server latency",
    "patterns": [
      "apiserver latency",
      "LongRunningRequest"
    ],
    "solution": "O problema **High API server latency** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "e5551a755936",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'High API server latency' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "API",
      "High",
      "latency",
      "server"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "API server down",
    "patterns": [
      "apiserver is down",
      "connection refused .* kube-apiserver"
    ],
    "solution": "O problema **API server down** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "034b68d16ec6",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'API server down' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "API",
      "down",
      "server"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "conntrack table is full",
    "patterns": [
      "conntrack table is full",
      "nf_conntrack: table full"
    ],
    "solution": "O problema **conntrack table is full** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "7f2735292049",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'conntrack table is full' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "conntrack",
      "full",
      "table"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "kube-proxy not working",
    "patterns": [
      "kube-proxy not working",
      "Failed to sync endpoint slices",
      "iptables-save failed"
    ],
    "solution": "O problema **kube-proxy not working** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "fc03f33433ec",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'kube-proxy not working' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "kube-proxy",
      "not",
      "working"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Scheduler not placing pods",
    "patterns": [
      "FailedScheduling",
      "re:scheduler cache is out of sync"
    ],
    "solution": "O problema **Scheduler not placing pods** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Falta de recursos no cluster, *requests* superestimados, *taints* sem *tolerations*, *affinity/selector* incompatíveis.\n#### Correções\n- Reduza *requests/limits* para *right-sizing* ou **escale** o cluster.\n- Ajuste `nodeSelector`/`nodeAffinity` para rótulos realmente presentes; adicione *tolerations* quando houver *taints*.\n- Revise `topologySpreadConstraints` e *PodDisruptionBudget* que podem bloquear o agendamento.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "e0af1fcf1ff9",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Scheduler not placing pods' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reduza *requests* ou escale nós; habilite/ajuste *Cluster Autoscaler*.",
      "Ajuste `nodeSelector`/`affinity`/`tolerations` para casar com os nós disponíveis.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Scheduler",
      "not",
      "placing",
      "pods"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Pod stuck Pending",
    "patterns": [
      "PodScheduled.*False",
      "PodScheduled.*Unschedulable"
    ],
    "solution": "O problema **Pod stuck Pending** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "f8a80fb54414",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Pod stuck Pending' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Pending",
      "Pod",
      "stuck"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Container cannot start",
    "patterns": [
      "ContainerCreating for too long",
      "re:Error: cannot start service"
    ],
    "solution": "O problema **Container cannot start** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "809b655df6ba",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Container cannot start' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Container",
      "cannot",
      "start"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Invalid resource quantity",
    "patterns": [
      "invalid resource quantity",
      "re:quantities must be positive values"
    ],
    "solution": "O problema **Invalid resource quantity** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "5cf0f6b26413",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Invalid resource quantity' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Invalid",
      "quantity",
      "resource"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Immutable field changed",
    "patterns": [
      "field is immutable",
      "re:Invalid value: .* field is immutable"
    ],
    "solution": "O problema **Immutable field changed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "804f302b1364",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Immutable field changed' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Immutable",
      "changed",
      "field"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Admission webhook denied",
    "patterns": [
      "denied by admission webhook",
      "re:admission webhook .* denied the request"
    ],
    "solution": "O problema **Admission webhook denied** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "987855f94686",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Admission webhook denied' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Admission",
      "denied",
      "webhook"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Webhook connection failure",
    "patterns": [
      "re:failed calling webhook .*: Post .* dial tcp .*: connect: connection refused",
      "x509: certificate signed by unknown authority"
    ],
    "solution": "O problema **Webhook connection failure** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "fa06e898dc4d",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Webhook connection failure' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Webhook",
      "connection",
      "failure"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "PodSecurity admission denied",
    "patterns": [
      "violates PodSecurity",
      "forbidden: violates PodSecurity"
    ],
    "solution": "O problema **PodSecurity admission denied** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "a553719235aa",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'PodSecurity admission denied' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "PodSecurity",
      "admission",
      "denied"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "ResourceQuota exceeded",
    "patterns": [
      "exceeded quota",
      "re:exceeded quota: .*"
    ],
    "solution": "O problema **ResourceQuota exceeded** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "098f00ccfc32",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'ResourceQuota exceeded' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "ResourceQuota",
      "exceeded"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "LimitRange violation",
    "patterns": [
      "must not exceed limit",
      "re:must be less than or equal to cpu limit"
    ],
    "solution": "O problema **LimitRange violation** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "4512df88b8d4",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'LimitRange violation' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "LimitRange",
      "violation"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Too many open files",
    "patterns": [
      "too many open files",
      "EMFILE"
    ],
    "solution": "O problema **Too many open files** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "6163ceb5496c",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Too many open files' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Too",
      "files",
      "many",
      "open"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Device or resource busy",
    "patterns": [
      "device or resource busy",
      "EBUSY"
    ],
    "solution": "O problema **Device or resource busy** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "cee04284e980",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Device or resource busy' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Device",
      "busy",
      "resource"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Segmentation fault",
    "patterns": [
      "Segmentation fault",
      "signal: segmentation fault",
      "SIGSEGV"
    ],
    "solution": "O problema **Segmentation fault** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "be7efc0fb3c0",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Segmentation fault' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Segmentation",
      "fault"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Java OutOfMemoryError",
    "patterns": [
      "java.lang.OutOfMemoryError",
      "GC overhead limit exceeded"
    ],
    "solution": "O problema **Java OutOfMemoryError** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "c66b6e33df45",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Java OutOfMemoryError' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Java",
      "OutOfMemoryError"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Panic in Go",
    "patterns": [
      "panic:",
      "runtime: out of memory"
    ],
    "solution": "O problema **Panic in Go** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "33cb2e7bcb2a",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Panic in Go' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Panic"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Back-off pulling image",
    "patterns": [
      "back-off pulling image",
      "Error response from daemon: manifest unknown"
    ],
    "solution": "O problema **Back-off pulling image** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Nome/tag inválidos, imagem inexistente, ou credenciais/egresso até o *registry* indisponíveis.\n#### Ações imediatas\n- Confirme *image* e *tag/digest* exatamente como publicadas.\n- Se privado: crie `Secret` tipo `docker-registry` e referencie em `imagePullSecrets`.\n- Teste no nó: `crictl pull <image>:<tag>` (ou `docker/podman`).\n#### Correções\n- Ajuste o nome totalmente qualificado (ex.: `gcr.io/proj/app:1.2.3` / `public.ecr.aws/...`).\n- Garanta permissões no *registry* e políticas de rede/egress liberadas.\n- Use `imagePullPolicy: IfNotPresent` (ou `Always` onde fizer sentido).\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "bde7bfe42039",
    "category": "Image/Registry",
    "severity": "medium",
    "explanation": "Descrição: 'Back-off pulling image' geralmente indica um problema na categoria Image/Registry. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó"
    ],
    "fix_steps": [
      "Corrija nome/tag da imagem e *imagePullSecrets*.",
      "Valide conectividade de rede ao *registry* (egresso/HTTP proxy).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Garanta imagePullSecrets corretos e acesso ao registry.",
      "Valide tag/digest e disponibilidade da imagem no registry."
    ],
    "tags": [
      "Back-off",
      "image",
      "pulling"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Secret not found",
    "patterns": [
      "secret .* not found",
      "re:secrets \\\".*\\\" not found"
    ],
    "solution": "O problema **Secret not found** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### AWS (EKS/IRSA/Storage)\n- **IRSA/STS**: confira *OIDC provider* e *trust policy* do *role*; anote o SA com `eks.amazonaws.com/role-arn`.\n- **EBS/EFS**: políticas IAM para `AttachVolume`, `Describe*` e permissões do driver CSI.\n- **S3/KMS**: `s3:PutObject/GetObject` e `kms:Decrypt/Encrypt` conforme necessidade; revise *bucket policy* e *key policy*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "7318d0ce4490",
    "category": "AWS/EKS",
    "severity": "medium",
    "explanation": "Descrição: 'Secret not found' geralmente indica um problema na categoria AWS/EKS. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Revise *trust policy* do IAM Role (IRSA), políticas do driver CSI e permissões S3/KMS.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Habilite OIDC do cluster (IRSA) e vincule a policy correta à ServiceAccount.",
      "Ajuste permissões IAM com base na ação negada (CloudTrail)."
    ],
    "tags": [
      "Secret",
      "found",
      "not"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "aws_permissions": [
      "ec2:Describe*",
      "ecr:GetAuthorizationToken",
      "elasticloadbalancing:*",
      "logs:*"
    ],
    "references": []
  },
  {
    "error": "ConfigMap not found",
    "patterns": [
      "configmap .* not found",
      "re:configmaps \\\".*\\\" not found"
    ],
    "solution": "O problema **ConfigMap not found** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "8ee7d8caf280",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'ConfigMap not found' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "ConfigMap",
      "found",
      "not"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Job deadline exceeded",
    "patterns": [
      "DeadlineExceeded",
      "re:Job .* has reached the specified backoff limit"
    ],
    "solution": "O problema **Job deadline exceeded** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "90ac83057385",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Job deadline exceeded' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Job",
      "deadline",
      "exceeded"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Image layer extraction failed",
    "patterns": [
      "failed to register layer",
      "re:error pulling image configuration.*"
    ],
    "solution": "O problema **Image layer extraction failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "82b775924db1",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Image layer extraction failed' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Image",
      "extraction",
      "failed",
      "layer"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "TLS: handshake timeout",
    "patterns": [
      "handshake timeout",
      "Client.Timeout exceeded while awaiting headers"
    ],
    "solution": "O problema **TLS: handshake timeout** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Conectividade de *Services*\n- Verifique `Service` ↔ *pods* via `selector`/labels; inspecione `endpoints`/`endpointslices`.\n- Valide `targetPort` e a aplicação escutando (`netstat -tlnp` dentro do contêiner).\n- Revise *NetworkPolicies* e *egress* do *namespace*.\n#### Ingress/Certificados\n- *404 default backend*: `serviceName`/`servicePort` e `pathType` incorretos são comuns.\n- **TLS**: crie `Secret` tipo `kubernetes.io/tls` com `tls.crt`/`tls.key`; cheque *CN/SAN* corretos.\n- Para `x509`/`handshake` erros, valide cadeia de certificados e *trust store* do upstream.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "06143a100c6a",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'TLS: handshake timeout' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija `selector`/labels do Service e confirme *endpoints*.",
      "Valide `targetPort` e que o app escuta na porta correta.",
      "Ajuste `path`, `pathType` e backends; corrija o `Secret` TLS (tipo `kubernetes.io/tls`).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "TLS",
      "handshake",
      "timeout"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Node clock skew",
    "patterns": [
      "x509: certificate has expired or is not yet valid",
      "certificate not yet valid"
    ],
    "solution": "O problema **Node clock skew** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "f6343cb96dbf",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'Node clock skew' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Node",
      "clock",
      "skew"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Pod evicted: memory",
    "patterns": [
      "evicted: The node was low on resource: memory",
      "Evicted: The node had condition: MemoryPressure"
    ],
    "solution": "O problema **Pod evicted: memory** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "3b668b9a4bc8",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Pod evicted: memory' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Pod",
      "evicted",
      "memory"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Pod evicted: disk",
    "patterns": [
      "evicted: The node was low on resource: ephemeral-storage",
      "DiskPressure"
    ],
    "solution": "O problema **Pod evicted: disk** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "8b400a8b843d",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Pod evicted: disk' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Pod",
      "disk",
      "evicted"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "ImagePull rate limit",
    "patterns": [
      "toomanyrequests: Rate exceeded"
    ],
    "solution": "O problema **ImagePull rate limit** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Nome/tag inválidos, imagem inexistente, ou credenciais/egresso até o *registry* indisponíveis.\n#### Ações imediatas\n- Confirme *image* e *tag/digest* exatamente como publicadas.\n- Se privado: crie `Secret` tipo `docker-registry` e referencie em `imagePullSecrets`.\n- Teste no nó: `crictl pull <image>:<tag>` (ou `docker/podman`).\n#### Correções\n- Ajuste o nome totalmente qualificado (ex.: `gcr.io/proj/app:1.2.3` / `public.ecr.aws/...`).\n- Garanta permissões no *registry* e políticas de rede/egress liberadas.\n- Use `imagePullPolicy: IfNotPresent` (ou `Always` onde fizer sentido).\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "7081e2fa00ea",
    "category": "Image/Registry",
    "severity": "medium",
    "explanation": "Descrição: 'ImagePull rate limit' geralmente indica um problema na categoria Image/Registry. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó"
    ],
    "fix_steps": [
      "Corrija nome/tag da imagem e *imagePullSecrets*.",
      "Valide conectividade de rede ao *registry* (egresso/HTTP proxy).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Garanta imagePullSecrets corretos e acesso ao registry.",
      "Valide tag/digest e disponibilidade da imagem no registry."
    ],
    "tags": [
      "ImagePull",
      "limit",
      "rate"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Node filesystem read-only",
    "patterns": [
      "Read-only file system on node",
      "overlayfs: failed to mount"
    ],
    "solution": "O problema **Node filesystem read-only** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Sistema de arquivos e permissões\n- **Read-only**: monte com `readOnly: false` onde precisa escrever.\n- Defina `securityContext`: `runAsUser`, `runAsGroup`, `fsGroup` para ownership correto.\n- Corrija `no such file` verificando `workingDir`, caminho do *entrypoint* e *scripts* executáveis (`chmod +x`).\n- **operation not permitted**: evite `privileged`; adicione apenas *capabilities* necessárias (ex.: `NET_ADMIN`).\n- Em ambientes com SELinux/AppArmor, ajuste *labels* ou *profiles* adequados.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "76638a0a78aa",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'Node filesystem read-only' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Monte com `readOnly: false` onde escreve e ajuste `fsGroup`/`runAsUser`.",
      "Corrija caminhos/`workingDir` e permissões de execução.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Node",
      "filesystem",
      "read-only"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Kubelet PLEG not healthy",
    "patterns": [
      "PLEG is not healthy"
    ],
    "solution": "O problema **Kubelet PLEG not healthy** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "bbb04a31fc62",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'Kubelet PLEG not healthy' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Kubelet",
      "PLEG",
      "healthy",
      "not"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Pod blocked by NetworkPolicy",
    "patterns": [
      "networkpolicy denied",
      "Connection timed out with NetworkPolicy"
    ],
    "solution": "O problema **Pod blocked by NetworkPolicy** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "222f15da3653",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Pod blocked by NetworkPolicy' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "NetworkPolicy",
      "Pod",
      "blocked"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Service type NodePort blocked",
    "patterns": [
      "NodePort service inaccessible",
      "ECONNREFUSED to <nodeIP>:<nodePort>"
    ],
    "solution": "O problema **Service type NodePort blocked** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Conectividade de *Services*\n- Verifique `Service` ↔ *pods* via `selector`/labels; inspecione `endpoints`/`endpointslices`.\n- Valide `targetPort` e a aplicação escutando (`netstat -tlnp` dentro do contêiner).\n- Revise *NetworkPolicies* e *egress* do *namespace*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "93b28e7b4d82",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'Service type NodePort blocked' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija `selector`/labels do Service e confirme *endpoints*.",
      "Valide `targetPort` e que o app escuta na porta correta.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "NodePort",
      "Service",
      "blocked",
      "type"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Pod priority preempted",
    "patterns": [
      "Preempted",
      "Preempted by higher priority pod"
    ],
    "solution": "O problema **Pod priority preempted** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "521faf47d8f4",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Pod priority preempted' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Pod",
      "preempted",
      "priority"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "HostPath permission denied",
    "patterns": [
      "hostPath .* permission denied",
      "re:cannot mount \\\"hostPath\\\".* permission denied"
    ],
    "solution": "O problema **HostPath permission denied** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Sistema de arquivos e permissões\n- **Read-only**: monte com `readOnly: false` onde precisa escrever.\n- Defina `securityContext`: `runAsUser`, `runAsGroup`, `fsGroup` para ownership correto.\n- Corrija `no such file` verificando `workingDir`, caminho do *entrypoint* e *scripts* executáveis (`chmod +x`).\n- **operation not permitted**: evite `privileged`; adicione apenas *capabilities* necessárias (ex.: `NET_ADMIN`).\n- Em ambientes com SELinux/AppArmor, ajuste *labels* ou *profiles* adequados.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "9f9674db78a6",
    "category": "RBAC/Auth",
    "severity": "high",
    "explanation": "Descrição: 'HostPath permission denied' geralmente indica um problema na categoria RBAC/Auth. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Monte com `readOnly: false` onde escreve e ajuste `fsGroup`/`runAsUser`.",
      "Corrija caminhos/`workingDir` e permissões de execução.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "HostPath",
      "denied",
      "permission"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "CSI driver not installed",
    "patterns": [
      "failed to find a persistentvolumeclaim to match",
      "CSI driver not found",
      "no volume plugin matched"
    ],
    "solution": "O problema **CSI driver not installed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "3032c44b59c7",
    "category": "Storage/CSI",
    "severity": "medium",
    "explanation": "Descrição: 'CSI driver not installed' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "CSI",
      "driver",
      "installed",
      "not"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "CSI attachment timeout",
    "patterns": [
      "timed out waiting for the condition while mounting volume",
      "AttachVolume.* timed out"
    ],
    "solution": "O problema **CSI attachment timeout** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Conectividade de *Services*\n- Verifique `Service` ↔ *pods* via `selector`/labels; inspecione `endpoints`/`endpointslices`.\n- Valide `targetPort` e a aplicação escutando (`netstat -tlnp` dentro do contêiner).\n- Revise *NetworkPolicies* e *egress* do *namespace*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "36921f838415",
    "category": "Storage/CSI",
    "severity": "high",
    "explanation": "Descrição: 'CSI attachment timeout' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Corrija `selector`/labels do Service e confirme *endpoints*.",
      "Valide `targetPort` e que o app escuta na porta correta.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "CSI",
      "attachment",
      "timeout"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Pod uses hostNetwork without permissions",
    "patterns": [
      "forbidden: use of host network is not allowed"
    ],
    "solution": "O problema **Pod uses hostNetwork without permissions** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "852b0577ca61",
    "category": "RBAC/Auth",
    "severity": "medium",
    "explanation": "Descrição: 'Pod uses hostNetwork without permissions' geralmente indica um problema na categoria RBAC/Auth. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Pod",
      "hostNetwork",
      "permissions",
      "uses",
      "without"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Pod uses hostPID/hostIPC denied",
    "patterns": [
      "forbidden: use of host pid is not allowed",
      "forbidden: use of host ipc is not allowed"
    ],
    "solution": "O problema **Pod uses hostPID/hostIPC denied** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "17bcb09d6143",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Pod uses hostPID/hostIPC denied' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Pod",
      "denied",
      "hostPID/hostIPC",
      "uses"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Capabilities denied",
    "patterns": [
      "forbidden: capability .* is not allowed",
      "cap_sys_admin not allowed"
    ],
    "solution": "O problema **Capabilities denied** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "b2d7e6bb8296",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Capabilities denied' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Capabilities",
      "denied"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "RunAsUser forbidden",
    "patterns": [
      "forbidden: must runAsNonRoot",
      "runAsUser is forbidden"
    ],
    "solution": "O problema **RunAsUser forbidden** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### RBAC/Autorização\n- Teste permissões: `kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>`.\n- Crie/ajuste `Role`/`ClusterRole` + `RoleBinding`/`ClusterRoleBinding`; garanta `serviceAccountName` correto no *pod*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "606f098eb522",
    "category": "RBAC/Auth",
    "severity": "high",
    "explanation": "Descrição: 'RunAsUser forbidden' geralmente indica um problema na categoria RBAC/Auth. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A"
    ],
    "fix_steps": [
      "Crie/ajuste `Role`/`ClusterRole` e *bindings*; valide com `kubectl auth can-i`.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "RunAsUser",
      "forbidden"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "HostPort denied",
    "patterns": [
      "forbidden: host ports are not allowed",
      "HostPort is not allowed"
    ],
    "solution": "O problema **HostPort denied** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "846f631adb09",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'HostPort denied' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "HostPort",
      "denied"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Privileged container forbidden",
    "patterns": [
      "forbidden: privileged containers are not allowed"
    ],
    "solution": "O problema **Privileged container forbidden** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### RBAC/Autorização\n- Teste permissões: `kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>`.\n- Crie/ajuste `Role`/`ClusterRole` + `RoleBinding`/`ClusterRoleBinding`; garanta `serviceAccountName` correto no *pod*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "2fd451037365",
    "category": "RBAC/Auth",
    "severity": "high",
    "explanation": "Descrição: 'Privileged container forbidden' geralmente indica um problema na categoria RBAC/Auth. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A"
    ],
    "fix_steps": [
      "Crie/ajuste `Role`/`ClusterRole` e *bindings*; valide com `kubectl auth can-i`.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Privileged",
      "container",
      "forbidden"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Sysctl forbidden",
    "patterns": [
      "forbidden sysctl",
      "unsafe sysctl not allowed"
    ],
    "solution": "O problema **Sysctl forbidden** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### RBAC/Autorização\n- Teste permissões: `kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>`.\n- Crie/ajuste `Role`/`ClusterRole` + `RoleBinding`/`ClusterRoleBinding`; garanta `serviceAccountName` correto no *pod*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "6f8f4c23af02",
    "category": "RBAC/Auth",
    "severity": "high",
    "explanation": "Descrição: 'Sysctl forbidden' geralmente indica um problema na categoria RBAC/Auth. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A"
    ],
    "fix_steps": [
      "Crie/ajuste `Role`/`ClusterRole` e *bindings*; valide com `kubectl auth can-i`.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Sysctl",
      "forbidden"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Downward API reference invalid",
    "patterns": [
      "fieldRef.* not supported",
      "status.podIP not found"
    ],
    "solution": "O problema **Downward API reference invalid** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "f97c081011ad",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Downward API reference invalid' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "API",
      "Downward",
      "invalid",
      "reference"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "PodAntiAffinity prevents scheduling",
    "patterns": [
      "requiredDuringSchedulingIgnoredDuringExecution",
      "matchExpressions.* prevents matching"
    ],
    "solution": "O problema **PodAntiAffinity prevents scheduling** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Falta de recursos no cluster, *requests* superestimados, *taints* sem *tolerations*, *affinity/selector* incompatíveis.\n#### Correções\n- Reduza *requests/limits* para *right-sizing* ou **escale** o cluster.\n- Ajuste `nodeSelector`/`nodeAffinity` para rótulos realmente presentes; adicione *tolerations* quando houver *taints*.\n- Revise `topologySpreadConstraints` e *PodDisruptionBudget* que podem bloquear o agendamento.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "c4b499e96692",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'PodAntiAffinity prevents scheduling' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reduza *requests* ou escale nós; habilite/ajuste *Cluster Autoscaler*.",
      "Ajuste `nodeSelector`/`affinity`/`tolerations` para casar com os nós disponíveis.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "PodAntiAffinity",
      "prevents",
      "scheduling"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Topology spread constraints blocked",
    "patterns": [
      "matchLabelKeys.* not satisfied",
      "topologySpreadConstraints"
    ],
    "solution": "O problema **Topology spread constraints blocked** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "3d0444195335",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Topology spread constraints blocked' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Topology",
      "blocked",
      "constraints",
      "spread"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Service external IP pending",
    "patterns": [
      "pending external IP",
      "type LoadBalancer.* pending"
    ],
    "solution": "O problema **Service external IP pending** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Conectividade de *Services*\n- Verifique `Service` ↔ *pods* via `selector`/labels; inspecione `endpoints`/`endpointslices`.\n- Valide `targetPort` e a aplicação escutando (`netstat -tlnp` dentro do contêiner).\n- Revise *NetworkPolicies* e *egress* do *namespace*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "6dd4f43a82ef",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Service external IP pending' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija `selector`/labels do Service e confirme *endpoints*.",
      "Valide `targetPort` e que o app escuta na porta correta.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Service",
      "external",
      "pending"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "API rate limit exceeded",
    "patterns": [
      "Too Many Requests",
      "re:throttling request .* due to client-side throttling"
    ],
    "solution": "O problema **API rate limit exceeded** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "07a29aa70a20",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'API rate limit exceeded' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "API",
      "exceeded",
      "limit",
      "rate"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Pod stuck Terminating",
    "patterns": [
      "Pod .* is terminating",
      "finalizers prevent deletion",
      "error killing pod",
      "Orphaned pod",
      "Terminating"
    ],
    "solution": "O problema **Pod stuck Terminating** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "a101617309fc",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Pod stuck Terminating' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Pod",
      "Terminating",
      "stuck"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Image pull unauthorized",
    "patterns": [
      "unauthorized: authentication required",
      "401 Unauthorized from registry"
    ],
    "solution": "O problema **Image pull unauthorized** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Nome/tag inválidos, imagem inexistente, ou credenciais/egresso até o *registry* indisponíveis.\n#### Ações imediatas\n- Confirme *image* e *tag/digest* exatamente como publicadas.\n- Se privado: crie `Secret` tipo `docker-registry` e referencie em `imagePullSecrets`.\n- Teste no nó: `crictl pull <image>:<tag>` (ou `docker/podman`).\n#### Correções\n- Ajuste o nome totalmente qualificado (ex.: `gcr.io/proj/app:1.2.3` / `public.ecr.aws/...`).\n- Garanta permissões no *registry* e políticas de rede/egress liberadas.\n- Use `imagePullPolicy: IfNotPresent` (ou `Always` onde fizer sentido).\n#### RBAC/Autorização\n- Teste permissões: `kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>`.\n- Crie/ajuste `Role`/`ClusterRole` + `RoleBinding`/`ClusterRoleBinding`; garanta `serviceAccountName` correto no *pod*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "35eb02483def",
    "category": "Image/Registry",
    "severity": "medium",
    "explanation": "Descrição: 'Image pull unauthorized' geralmente indica um problema na categoria Image/Registry. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A"
    ],
    "fix_steps": [
      "Corrija nome/tag da imagem e *imagePullSecrets*.",
      "Valide conectividade de rede ao *registry* (egresso/HTTP proxy).",
      "Crie/ajuste `Role`/`ClusterRole` e *bindings*; valide com `kubectl auth can-i`.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Garanta imagePullSecrets corretos e acesso ao registry.",
      "Valide tag/digest e disponibilidade da imagem no registry."
    ],
    "tags": [
      "Image",
      "pull",
      "unauthorized"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Image manifest unknown",
    "patterns": [
      "manifest unknown",
      "manifest not found"
    ],
    "solution": "O problema **Image manifest unknown** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "70b9db64a219",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Image manifest unknown' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Image",
      "manifest",
      "unknown"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Invalid mount path",
    "patterns": [
      "is not absolute",
      "invalid mount path"
    ],
    "solution": "O problema **Invalid mount path** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "eb940e3193b1",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Invalid mount path' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Invalid",
      "mount",
      "path"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "PVC access mode mismatch",
    "patterns": [
      "does not support requested access mode",
      "re:PV .* does not support accessModes"
    ],
    "solution": "O problema **PVC access mode mismatch** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "f7650996a327",
    "category": "Storage/CSI",
    "severity": "medium",
    "explanation": "Descrição: 'PVC access mode mismatch' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "PVC",
      "access",
      "mismatch",
      "mode"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "ReadWriteMany not supported",
    "patterns": [
      "provisioner does not support ReadWriteMany"
    ],
    "solution": "O problema **ReadWriteMany not supported** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "57f4482b932a",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'ReadWriteMany not supported' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "ReadWriteMany",
      "not",
      "supported"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "PodSecurityContext fsGroup invalid",
    "patterns": [
      "fsGroup is not allowed",
      "fsGroup must be in the ranges"
    ],
    "solution": "O problema **PodSecurityContext fsGroup invalid** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "2c79f290aed0",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'PodSecurityContext fsGroup invalid' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "PodSecurityContext",
      "fsGroup",
      "invalid"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Node affinity unsatisfiable",
    "patterns": [
      "node(s) didn't match Pod's node affinity",
      "RequiredDuringScheduling.* not matched"
    ],
    "solution": "O problema **Node affinity unsatisfiable** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "473a487eeaa0",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'Node affinity unsatisfiable' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Node",
      "affinity",
      "unsatisfiable"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Image pull network unreachable",
    "patterns": [
      "Temporary failure in name resolution",
      "no route to host"
    ],
    "solution": "O problema **Image pull network unreachable** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Nome/tag inválidos, imagem inexistente, ou credenciais/egresso até o *registry* indisponíveis.\n#### Ações imediatas\n- Confirme *image* e *tag/digest* exatamente como publicadas.\n- Se privado: crie `Secret` tipo `docker-registry` e referencie em `imagePullSecrets`.\n- Teste no nó: `crictl pull <image>:<tag>` (ou `docker/podman`).\n#### Correções\n- Ajuste o nome totalmente qualificado (ex.: `gcr.io/proj/app:1.2.3` / `public.ecr.aws/...`).\n- Garanta permissões no *registry* e políticas de rede/egress liberadas.\n- Use `imagePullPolicy: IfNotPresent` (ou `Always` onde fizer sentido).\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "2e12be2993de",
    "category": "Image/Registry",
    "severity": "medium",
    "explanation": "Descrição: 'Image pull network unreachable' geralmente indica um problema na categoria Image/Registry. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó"
    ],
    "fix_steps": [
      "Corrija nome/tag da imagem e *imagePullSecrets*.",
      "Valide conectividade de rede ao *registry* (egresso/HTTP proxy).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Garanta imagePullSecrets corretos e acesso ao registry.",
      "Valide tag/digest e disponibilidade da imagem no registry."
    ],
    "tags": [
      "Image",
      "network",
      "pull",
      "unreachable"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "CoreDNS CrashLoop",
    "patterns": [
      "coredns.* CrashLoopBackOff",
      "plugin/loop: seen more than 5 dns requests with same id"
    ],
    "solution": "O problema **CoreDNS CrashLoop** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Falha no *entrypoint*/`command`, dependência externa indisponível, *config* ausente, ou *panic* da aplicação.\n- *Probes* agressivas derrubando o processo durante a inicialização.\n#### Ações imediatas\n- Veja o contêiner anterior: `kubectl logs <pod> -n <ns> --previous` (indica a causa de saída).\n- Descreva o pod e eventos: `kubectl describe pod <pod> -n <ns>` (erros de mount/env/args).\n#### Correções\n- Corrija env/args/arquivos requeridos; torne scripts executáveis (`chmod +x`).\n- Se devido a *readiness/liveness*, relaxe `initialDelaySeconds`, `periodSeconds`, `timeoutSeconds` e `failureThreshold`.\n- Aumente `terminationGracePeriodSeconds` se precisar finalizar com *graceful shutdown*.\n#### DNS/CoreDNS\n- Teste dentro do *pod*: `nslookup`/`dig` para o FQDN; cheque `/etc/resolv.conf`.\n- Reinicie `coredns` se travado; confirme *upstream* acessível e políticas de rede liberando DNS.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "ef70b8555fc1",
    "category": "Networking/DNS",
    "severity": "high",
    "explanation": "Descrição: Falhas de resolução DNS (ex.: 'no such host', 'NXDOMAIN') indicam que o nome não pode ser resolvido pelo CoreDNS ou pelo DNS externo.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl -n kube-system logs deploy/coredns --tail=200",
      "kubectl exec -it <pod> -n <ns> -- nslookup <host>"
    ],
    "fix_steps": [
      "Corrija `command`/`args`/`entrypoint`; torne scripts executáveis.",
      "Revise *probes* e aumente tempos/thresholds conforme necessidade.",
      "Corrija o FQDN/hostname; confira `coredns` e DNS *upstream*.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Corrija o FQDN/hostname e verifique se há registros A/CNAME/TXT válidos.",
      "Se for serviço K8s, confirme Service/Endpoints e o sufixo .svc.cluster.local.",
      "Cheque políticas de rede/egress e o acesso ao DNS upstream."
    ],
    "tags": [
      "CoreDNS",
      "CrashLoop"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl -n kube-system logs deploy/coredns --tail=200",
      "kubectl exec -it <pod> -n <ns> -- nslookup <host>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "CoreDNS config error",
    "patterns": [
      "Failed to start CoreDNS",
      "Error loading configuration: .*"
    ],
    "solution": "O problema **CoreDNS config error** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### DNS/CoreDNS\n- Teste dentro do *pod*: `nslookup`/`dig` para o FQDN; cheque `/etc/resolv.conf`.\n- Reinicie `coredns` se travado; confirme *upstream* acessível e políticas de rede liberando DNS.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "7e937149dc6a",
    "category": "Networking/DNS",
    "severity": "high",
    "explanation": "Descrição: Falhas de resolução DNS (ex.: 'no such host', 'NXDOMAIN') indicam que o nome não pode ser resolvido pelo CoreDNS ou pelo DNS externo.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl -n kube-system logs deploy/coredns --tail=200",
      "kubectl exec -it <pod> -n <ns> -- nslookup <host>"
    ],
    "fix_steps": [
      "Corrija o FQDN/hostname; confira `coredns` e DNS *upstream*.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Corrija o FQDN/hostname e verifique se há registros A/CNAME/TXT válidos.",
      "Se for serviço K8s, confirme Service/Endpoints e o sufixo .svc.cluster.local.",
      "Cheque políticas de rede/egress e o acesso ao DNS upstream."
    ],
    "tags": [
      "CoreDNS",
      "config",
      "error"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl -n kube-system logs deploy/coredns --tail=200",
      "kubectl exec -it <pod> -n <ns> -- nslookup <host>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Kubelet certificate issue",
    "patterns": [
      "failed to verify certificate",
      "x509: certificate signed by unknown authority"
    ],
    "solution": "O problema **Kubelet certificate issue** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "4a330fec0922",
    "category": "Certificates/ACME",
    "severity": "medium",
    "explanation": "Descrição: 'Kubelet certificate issue' geralmente indica um problema na categoria Certificates/ACME. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Kubelet",
      "certificate",
      "issue"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "APIServer authorization error",
    "patterns": [
      "Forbidden (user=system:serviceaccount",
      "re:RBAC: access denied"
    ],
    "solution": "O problema **APIServer authorization error** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "68c5d9241b74",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'APIServer authorization error' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "APIServer",
      "authorization",
      "error"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Mutating webhook timeout",
    "patterns": [
      "admission webhook .* did not respond",
      "re:context deadline exceeded.* calling webhook"
    ],
    "solution": "O problema **Mutating webhook timeout** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Conectividade de *Services*\n- Verifique `Service` ↔ *pods* via `selector`/labels; inspecione `endpoints`/`endpointslices`.\n- Valide `targetPort` e a aplicação escutando (`netstat -tlnp` dentro do contêiner).\n- Revise *NetworkPolicies* e *egress* do *namespace*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "a419b432c449",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Mutating webhook timeout' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija `selector`/labels do Service e confirme *endpoints*.",
      "Valide `targetPort` e que o app escuta na porta correta.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Mutating",
      "timeout",
      "webhook"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Long image build tag mismatch",
    "patterns": [
      "ImagePullBackOff .* latest",
      "Always pull with 'latest'"
    ],
    "solution": "O problema **Long image build tag mismatch** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "52041ee042ef",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Long image build tag mismatch' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Long",
      "build",
      "image",
      "mismatch",
      "tag"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Forbidden hostPath /var/run/docker.sock",
    "patterns": [
      "/var/run/docker.sock is forbidden",
      "hostPath .* docker.sock .* forbidden"
    ],
    "solution": "O problema **Forbidden hostPath /var/run/docker.sock** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### RBAC/Autorização\n- Teste permissões: `kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>`.\n- Crie/ajuste `Role`/`ClusterRole` + `RoleBinding`/`ClusterRoleBinding`; garanta `serviceAccountName` correto no *pod*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "a00b01b2803b",
    "category": "RBAC/Auth",
    "severity": "high",
    "explanation": "Descrição: 'Forbidden hostPath /var/run/docker.sock' geralmente indica um problema na categoria RBAC/Auth. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A"
    ],
    "fix_steps": [
      "Crie/ajuste `Role`/`ClusterRole` e *bindings*; valide com `kubectl auth can-i`.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "/var/run/docker",
      "Forbidden",
      "hostPath",
      "sock"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Ephemeral storage exceeded",
    "patterns": [
      "evicted: The node was low on resource: ephemeral-storage",
      "disk usage exceeded"
    ],
    "solution": "O problema **Ephemeral storage exceeded** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "6f6296d006c3",
    "category": "Storage/CSI",
    "severity": "medium",
    "explanation": "Descrição: 'Ephemeral storage exceeded' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "Ephemeral",
      "exceeded",
      "storage"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Pod DNS policy misconfigured",
    "patterns": [
      "nameserver .* refused",
      "reply from unexpected source"
    ],
    "solution": "O problema **Pod DNS policy misconfigured** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### DNS/CoreDNS\n- Teste dentro do *pod*: `nslookup`/`dig` para o FQDN; cheque `/etc/resolv.conf`.\n- Reinicie `coredns` se travado; confirme *upstream* acessível e políticas de rede liberando DNS.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "785b456173a0",
    "category": "Networking/DNS",
    "severity": "medium",
    "explanation": "Descrição: Falhas de resolução DNS (ex.: 'no such host', 'NXDOMAIN') indicam que o nome não pode ser resolvido pelo CoreDNS ou pelo DNS externo.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl -n kube-system logs deploy/coredns --tail=200",
      "kubectl exec -it <pod> -n <ns> -- nslookup <host>"
    ],
    "fix_steps": [
      "Corrija o FQDN/hostname; confira `coredns` e DNS *upstream*.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Corrija o FQDN/hostname e verifique se há registros A/CNAME/TXT válidos.",
      "Se for serviço K8s, confirme Service/Endpoints e o sufixo .svc.cluster.local.",
      "Cheque políticas de rede/egress e o acesso ao DNS upstream."
    ],
    "tags": [
      "DNS",
      "Pod",
      "misconfigured",
      "policy"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl -n kube-system logs deploy/coredns --tail=200",
      "kubectl exec -it <pod> -n <ns> -- nslookup <host>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Service selector mismatch",
    "patterns": [
      "no endpoints available",
      "EndpointSlice has 0 endpoints"
    ],
    "solution": "O problema **Service selector mismatch** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Conectividade de *Services*\n- Verifique `Service` ↔ *pods* via `selector`/labels; inspecione `endpoints`/`endpointslices`.\n- Valide `targetPort` e a aplicação escutando (`netstat -tlnp` dentro do contêiner).\n- Revise *NetworkPolicies* e *egress* do *namespace*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "1e4bd50ec356",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Service selector mismatch' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija `selector`/labels do Service e confirme *endpoints*.",
      "Valide `targetPort` e que o app escuta na porta correta.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Service",
      "mismatch",
      "selector"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Pod readiness gate failed",
    "patterns": [
      "ReadinessGates not satisfied",
      "condition .* not True"
    ],
    "solution": "O problema **Pod readiness gate failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "a6c2acdcdbd6",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Pod readiness gate failed' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Pod",
      "failed",
      "gate",
      "readiness"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "CSI NodePublishVolume failed",
    "patterns": [
      "NodePublishVolume .* failed",
      "mount propagation not supported"
    ],
    "solution": "O problema **CSI NodePublishVolume failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "cdaa5b46d009",
    "category": "Storage/CSI",
    "severity": "high",
    "explanation": "Descrição: 'CSI NodePublishVolume failed' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "CSI",
      "NodePublishVolume",
      "failed"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "ServiceAccount token projected volume error",
    "patterns": [
      "failed to fetch token",
      "token expired"
    ],
    "solution": "O problema **ServiceAccount token projected volume error** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "b86b171ad7b0",
    "category": "Storage/CSI",
    "severity": "high",
    "explanation": "Descrição: 'ServiceAccount token projected volume error' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "ServiceAccount",
      "error",
      "projected",
      "token",
      "volume"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Kubelet can't pull image (proxy)",
    "patterns": [
      "Proxy Authentication Required",
      "407 Proxy Authentication Required"
    ],
    "solution": "O problema **Kubelet can't pull image (proxy)** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Nome/tag inválidos, imagem inexistente, ou credenciais/egresso até o *registry* indisponíveis.\n#### Ações imediatas\n- Confirme *image* e *tag/digest* exatamente como publicadas.\n- Se privado: crie `Secret` tipo `docker-registry` e referencie em `imagePullSecrets`.\n- Teste no nó: `crictl pull <image>:<tag>` (ou `docker/podman`).\n#### Correções\n- Ajuste o nome totalmente qualificado (ex.: `gcr.io/proj/app:1.2.3` / `public.ecr.aws/...`).\n- Garanta permissões no *registry* e políticas de rede/egress liberadas.\n- Use `imagePullPolicy: IfNotPresent` (ou `Always` onde fizer sentido).\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "769ebcfdbfbf",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'Kubelet can't pull image (proxy)' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó"
    ],
    "fix_steps": [
      "Corrija nome/tag da imagem e *imagePullSecrets*.",
      "Valide conectividade de rede ao *registry* (egresso/HTTP proxy).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Kubelet",
      "can",
      "image",
      "proxy",
      "pull"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Node GPU device plugin error",
    "patterns": [
      "NVIDIA device plugin failed",
      "failed to initialize NVML"
    ],
    "solution": "O problema **Node GPU device plugin error** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "368bee07efcd",
    "category": "Node/Cluster",
    "severity": "high",
    "explanation": "Descrição: 'Node GPU device plugin error' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "GPU",
      "Node",
      "device",
      "error",
      "plugin"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "AWS Permission Denied",
    "solution": "O problema **AWS Permission Denied** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Sistema de arquivos e permissões\n- **Read-only**: monte com `readOnly: false` onde precisa escrever.\n- Defina `securityContext`: `runAsUser`, `runAsGroup`, `fsGroup` para ownership correto.\n- Corrija `no such file` verificando `workingDir`, caminho do *entrypoint* e *scripts* executáveis (`chmod +x`).\n- **operation not permitted**: evite `privileged`; adicione apenas *capabilities* necessárias (ex.: `NET_ADMIN`).\n- Em ambientes com SELinux/AppArmor, ajuste *labels* ou *profiles* adequados.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "patterns": [
      "aws permission denied"
    ],
    "id": "aa089db2bd0f",
    "category": "AWS/EKS",
    "severity": "high",
    "explanation": "Descrição: 'AWS Permission Denied' geralmente indica um problema na categoria AWS/EKS. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Monte com `readOnly: false` onde escreve e ajuste `fsGroup`/`runAsUser`.",
      "Corrija caminhos/`workingDir` e permissões de execução.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Habilite OIDC do cluster (IRSA) e vincule a policy correta à ServiceAccount.",
      "Ajuste permissões IAM com base na ação negada (CloudTrail)."
    ],
    "tags": [
      "AWS",
      "Denied",
      "Permission"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "aws_permissions": [
      "ec2:Describe*",
      "ecr:GetAuthorizationToken",
      "elasticloadbalancing:*",
      "logs:*"
    ],
    "references": []
  },
  {
    "error": "Unable to locate credentials. You can configure credentials by running \"aws configure\".",
    "solution": "O problema **Unable to locate credentials. You can configure credentials by running \"aws configure\".** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "patterns": [
      "Unable to locate credentials. You can configure credentials by running \"aws configure\".",
      "Unable to locate credentials"
    ],
    "id": "043ef0774762",
    "category": "AWS/EKS",
    "severity": "medium",
    "explanation": "Descrição: 'Unable to locate credentials. You can configure credentials by running \"aws configure\".' geralmente indica um problema na categoria AWS/EKS. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Habilite OIDC do cluster (IRSA) e vincule a policy correta à ServiceAccount.",
      "Ajuste permissões IAM com base na ação negada (CloudTrail)."
    ],
    "tags": [
      "Unable",
      "You",
      "can",
      "configure",
      "credentials",
      "locate"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "aws_permissions": [
      "ec2:Describe*",
      "ecr:GetAuthorizationToken",
      "elasticloadbalancing:*",
      "logs:*"
    ],
    "references": []
  },
  {
    "error": "Invalid Ingress API version",
    "patterns": [
      "no matches for kind \"Ingress\" in version \"extensions/v1beta1\"",
      "no matches for kind \"Ingress\" in version \"networking.k8s.io/v1beta1\""
    ],
    "solution": "O problema **Invalid Ingress API version** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Ingress/Certificados\n- *404 default backend*: `serviceName`/`servicePort` e `pathType` incorretos são comuns.\n- **TLS**: crie `Secret` tipo `kubernetes.io/tls` com `tls.crt`/`tls.key`; cheque *CN/SAN* corretos.\n- Para `x509`/`handshake` erros, valide cadeia de certificados e *trust store* do upstream.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "76648c69cc40",
    "category": "Ingress",
    "severity": "medium",
    "explanation": "Descrição: 'Invalid Ingress API version' geralmente indica um problema na categoria Ingress. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Ajuste `path`, `pathType` e backends; corrija o `Secret` TLS (tipo `kubernetes.io/tls`).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "API",
      "Ingress",
      "Invalid",
      "version"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "CRD kind not recognized",
    "patterns": [
      "re:no matches for kind \\\".*\\\" in version \\\".*\\\"",
      "error validating data: ValidationError: unknown field"
    ],
    "solution": "O problema **CRD kind not recognized** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "27fb7df7e990",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'CRD kind not recognized' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "CRD",
      "kind",
      "not",
      "recognized"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "cert-manager: order failed to finalize",
    "patterns": [
      "cert-manager.* Failed to finalize order",
      "Order .* marked as invalid"
    ],
    "solution": "O problema **cert-manager: order failed to finalize** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "b2052c45496e",
    "category": "Certificates/ACME",
    "severity": "high",
    "explanation": "Descrição: 'cert-manager: order failed to finalize' geralmente indica um problema na categoria Certificates/ACME. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "cert-manager",
      "failed",
      "finalize",
      "order"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "ACME rate limited",
    "patterns": [
      "429 urn:ietf:params:acme:error:rateLimited",
      "rateLimited: Error creating new order"
    ],
    "solution": "O problema **ACME rate limited** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "9bebd9a16559",
    "category": "Certificates/ACME",
    "severity": "medium",
    "explanation": "Descrição: 'ACME rate limited' geralmente indica um problema na categoria Certificates/ACME. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "ACME",
      "limited",
      "rate"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "HTTP-01 self-check failed",
    "patterns": [
      "Waiting for HTTP-01 challenge propagation: wrong status code '404'",
      "Challenge self check failed"
    ],
    "solution": "O problema **HTTP-01 self-check failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "1669cfa2863a",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'HTTP-01 self-check failed' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "HTTP-01",
      "failed",
      "self-check"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Service targetPort not found",
    "patterns": [
      "re:spec\\.ports\\[\\d+\\]\\.targetPort: Not found",
      "targetPort not found in Pod"
    ],
    "solution": "O problema **Service targetPort not found** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Conectividade de *Services*\n- Verifique `Service` ↔ *pods* via `selector`/labels; inspecione `endpoints`/`endpointslices`.\n- Valide `targetPort` e a aplicação escutando (`netstat -tlnp` dentro do contêiner).\n- Revise *NetworkPolicies* e *egress* do *namespace*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "35fe57ae5623",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Service targetPort not found' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija `selector`/labels do Service e confirme *endpoints*.",
      "Valide `targetPort` e que o app escuta na porta correta.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Service",
      "found",
      "not",
      "targetPort"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "runAsNonRoot conflicts with image",
    "patterns": [
      "container has runAsNonRoot and image will run as root",
      "must runAsNonRoot"
    ],
    "solution": "O problema **runAsNonRoot conflicts with image** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "cca446ad4b47",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'runAsNonRoot conflicts with image' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "conflicts",
      "image",
      "runAsNonRoot",
      "with"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Failed to fetch anonymous token (registry)",
    "patterns": [
      "failed to fetch anonymous token: unexpected status: 401 Unauthorized",
      "failed to authorize: rpc error: code = Unknown desc = failed to fetch anonymous token"
    ],
    "solution": "O problema **Failed to fetch anonymous token (registry)** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "54fc6dad6eca",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Failed to fetch anonymous token (registry)' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Failed",
      "anonymous",
      "fetch",
      "registry",
      "token"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Image pull TLS timeout",
    "patterns": [
      "Client.Timeout exceeded while awaiting headers",
      "net/http: TLS handshake timeout"
    ],
    "solution": "O problema **Image pull TLS timeout** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Nome/tag inválidos, imagem inexistente, ou credenciais/egresso até o *registry* indisponíveis.\n#### Ações imediatas\n- Confirme *image* e *tag/digest* exatamente como publicadas.\n- Se privado: crie `Secret` tipo `docker-registry` e referencie em `imagePullSecrets`.\n- Teste no nó: `crictl pull <image>:<tag>` (ou `docker/podman`).\n#### Correções\n- Ajuste o nome totalmente qualificado (ex.: `gcr.io/proj/app:1.2.3` / `public.ecr.aws/...`).\n- Garanta permissões no *registry* e políticas de rede/egress liberadas.\n- Use `imagePullPolicy: IfNotPresent` (ou `Always` onde fizer sentido).\n#### Conectividade de *Services*\n- Verifique `Service` ↔ *pods* via `selector`/labels; inspecione `endpoints`/`endpointslices`.\n- Valide `targetPort` e a aplicação escutando (`netstat -tlnp` dentro do contêiner).\n- Revise *NetworkPolicies* e *egress* do *namespace*.\n#### Ingress/Certificados\n- *404 default backend*: `serviceName`/`servicePort` e `pathType` incorretos são comuns.\n- **TLS**: crie `Secret` tipo `kubernetes.io/tls` com `tls.crt`/`tls.key`; cheque *CN/SAN* corretos.\n- Para `x509`/`handshake` erros, valide cadeia de certificados e *trust store* do upstream.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "5b25ee97ad82",
    "category": "Image/Registry",
    "severity": "high",
    "explanation": "Descrição: 'Image pull TLS timeout' geralmente indica um problema na categoria Image/Registry. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint"
    ],
    "fix_steps": [
      "Corrija nome/tag da imagem e *imagePullSecrets*.",
      "Valide conectividade de rede ao *registry* (egresso/HTTP proxy).",
      "Corrija `selector`/labels do Service e confirme *endpoints*.",
      "Valide `targetPort` e que o app escuta na porta correta.",
      "Ajuste `path`, `pathType` e backends; corrija o `Secret` TLS (tipo `kubernetes.io/tls`).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Garanta imagePullSecrets corretos e acesso ao registry.",
      "Valide tag/digest e disponibilidade da imagem no registry."
    ],
    "tags": [
      "Image",
      "TLS",
      "pull",
      "timeout"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó",
      "kubectl get svc,endpoints,endpointslices -n <ns>",
      "kubectl port-forward pod/<pod> -n <ns> <localPort>:<containerPort>  # testar endpoint",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "CNI bridge not found",
    "patterns": [
      "cni0: link not found",
      "failed to setup network for sandbox: failed to find bridge cni0"
    ],
    "solution": "O problema **CNI bridge not found** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### CNI/Runtime\n- *Pod sandbox* falhas normalmente indicam CNI ou container runtime com problemas.\n- Confira *daemonset* do CNI (Calico/Cilium/Weave) e logs do `kubelet`/`containerd`.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "ffc3fae45d87",
    "category": "CNI/Networking",
    "severity": "medium",
    "explanation": "Descrição: 'CNI bridge not found' geralmente indica um problema na categoria CNI/Networking. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "CNI",
      "bridge",
      "found",
      "not"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "iptables-restore failed",
    "patterns": [
      "iptables-restore: line .* failed",
      "kube-proxy.* iptables-save failed"
    ],
    "solution": "O problema **iptables-restore failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "e5b989a69e49",
    "category": "CNI/Networking",
    "severity": "high",
    "explanation": "Descrição: 'iptables-restore failed' geralmente indica um problema na categoria CNI/Networking. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "failed",
      "iptables-restore"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Calico IPAM allocation error",
    "patterns": [
      "calico.* IPAM allocation error",
      "failed to assign IP address to pod"
    ],
    "solution": "O problema **Calico IPAM allocation error** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "520ea3419da3",
    "category": "CNI/Networking",
    "severity": "high",
    "explanation": "Descrição: 'Calico IPAM allocation error' geralmente indica um problema na categoria CNI/Networking. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Calico",
      "IPAM",
      "allocation",
      "error"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Cilium not ready",
    "patterns": [
      "cilium.* is not ready",
      "Cilium API unreachable"
    ],
    "solution": "O problema **Cilium not ready** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "fce1dc4fc95b",
    "category": "CNI/Networking",
    "severity": "medium",
    "explanation": "Descrição: 'Cilium not ready' geralmente indica um problema na categoria CNI/Networking. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Cilium",
      "not",
      "ready"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "AWS LB Controller AccessDenied",
    "patterns": [
      "AccessDenied: User .* is not authorized to perform: elasticloadbalancing:CreateLoadBalancer",
      "re:failed to reconcile: .* AccessDenied"
    ],
    "solution": "O problema **AWS LB Controller AccessDenied** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "0e0814b2c669",
    "category": "AWS/EKS",
    "severity": "high",
    "explanation": "Descrição: 'AWS LB Controller AccessDenied' geralmente indica um problema na categoria AWS/EKS. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Habilite OIDC do cluster (IRSA) e vincule a policy correta à ServiceAccount.",
      "Ajuste permissões IAM com base na ação negada (CloudTrail)."
    ],
    "tags": [
      "AWS",
      "AccessDenied",
      "Controller"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "aws_permissions": [
      "ec2:Describe*",
      "ecr:GetAuthorizationToken",
      "elasticloadbalancing:*",
      "logs:*"
    ],
    "references": []
  },
  {
    "error": "AWS LB Controller: no suitable subnets",
    "patterns": [
      "failed to build load balancer due to no suitable subnets",
      "subnets not tagged for auto-discovery"
    ],
    "solution": "O problema **AWS LB Controller: no suitable subnets** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "1d72db075982",
    "category": "AWS/EKS",
    "severity": "medium",
    "explanation": "Descrição: 'AWS LB Controller: no suitable subnets' geralmente indica um problema na categoria AWS/EKS. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Habilite OIDC do cluster (IRSA) e vincule a policy correta à ServiceAccount.",
      "Ajuste permissões IAM com base na ação negada (CloudTrail)."
    ],
    "tags": [
      "AWS",
      "Controller",
      "subnets",
      "suitable"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "aws_permissions": [
      "ec2:Describe*",
      "ecr:GetAuthorizationToken",
      "elasticloadbalancing:*",
      "logs:*"
    ],
    "references": []
  },
  {
    "error": "AWS VPC CNI exhausted IPs",
    "patterns": [
      "ipamd: prefix has no available addresses",
      "failed to assign an IP address to pod"
    ],
    "solution": "O problema **AWS VPC CNI exhausted IPs** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### CNI/Runtime\n- *Pod sandbox* falhas normalmente indicam CNI ou container runtime com problemas.\n- Confira *daemonset* do CNI (Calico/Cilium/Weave) e logs do `kubelet`/`containerd`.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "1076af017b8a",
    "category": "AWS/EKS",
    "severity": "medium",
    "explanation": "Descrição: 'AWS VPC CNI exhausted IPs' geralmente indica um problema na categoria AWS/EKS. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Habilite OIDC do cluster (IRSA) e vincule a policy correta à ServiceAccount.",
      "Ajuste permissões IAM com base na ação negada (CloudTrail)."
    ],
    "tags": [
      "AWS",
      "CNI",
      "IPs",
      "VPC",
      "exhausted"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "aws_permissions": [
      "ec2:Describe*",
      "ecr:GetAuthorizationToken",
      "elasticloadbalancing:*",
      "logs:*"
    ],
    "references": []
  },
  {
    "error": "IRSA invalid identity token",
    "patterns": [
      "InvalidIdentityToken",
      "could not assume role with web identity"
    ],
    "solution": "O problema **IRSA invalid identity token** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### AWS (EKS/IRSA/Storage)\n- **IRSA/STS**: confira *OIDC provider* e *trust policy* do *role*; anote o SA com `eks.amazonaws.com/role-arn`.\n- **EBS/EFS**: políticas IAM para `AttachVolume`, `Describe*` e permissões do driver CSI.\n- **S3/KMS**: `s3:PutObject/GetObject` e `kms:Decrypt/Encrypt` conforme necessidade; revise *bucket policy* e *key policy*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "ee4f4b0cdf5b",
    "category": "AWS/EKS",
    "severity": "medium",
    "explanation": "Descrição: 'IRSA invalid identity token' geralmente indica um problema na categoria AWS/EKS. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Revise *trust policy* do IAM Role (IRSA), políticas do driver CSI e permissões S3/KMS.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Habilite OIDC do cluster (IRSA) e vincule a policy correta à ServiceAccount.",
      "Ajuste permissões IAM com base na ação negada (CloudTrail)."
    ],
    "tags": [
      "IRSA",
      "identity",
      "invalid",
      "token"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "aws_permissions": [
      "ec2:Describe*",
      "ecr:GetAuthorizationToken",
      "elasticloadbalancing:*",
      "logs:*"
    ],
    "references": []
  },
  {
    "error": "IRSA OIDC provider not found",
    "patterns": [
      "No OpenIDConnect provider found in your account",
      "oidc: JWT signature verification failed"
    ],
    "solution": "O problema **IRSA OIDC provider not found** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### AWS (EKS/IRSA/Storage)\n- **IRSA/STS**: confira *OIDC provider* e *trust policy* do *role*; anote o SA com `eks.amazonaws.com/role-arn`.\n- **EBS/EFS**: políticas IAM para `AttachVolume`, `Describe*` e permissões do driver CSI.\n- **S3/KMS**: `s3:PutObject/GetObject` e `kms:Decrypt/Encrypt` conforme necessidade; revise *bucket policy* e *key policy*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "297b8e970a28",
    "category": "AWS/EKS",
    "severity": "medium",
    "explanation": "Descrição: 'IRSA OIDC provider not found' geralmente indica um problema na categoria AWS/EKS. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Revise *trust policy* do IAM Role (IRSA), políticas do driver CSI e permissões S3/KMS.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Habilite OIDC do cluster (IRSA) e vincule a policy correta à ServiceAccount.",
      "Ajuste permissões IAM com base na ação negada (CloudTrail)."
    ],
    "tags": [
      "IRSA",
      "OIDC",
      "found",
      "not",
      "provider"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "aws_permissions": [
      "ec2:Describe*",
      "ecr:GetAuthorizationToken",
      "elasticloadbalancing:*",
      "logs:*"
    ],
    "references": []
  },
  {
    "error": "ECR GetAuthorizationToken denied",
    "patterns": [
      "AccessDeniedException: User .* is not authorized to perform: ecr:GetAuthorizationToken",
      "cannot retrieve repository credentials"
    ],
    "solution": "O problema **ECR GetAuthorizationToken denied** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### AWS (EKS/IRSA/Storage)\n- **IRSA/STS**: confira *OIDC provider* e *trust policy* do *role*; anote o SA com `eks.amazonaws.com/role-arn`.\n- **EBS/EFS**: políticas IAM para `AttachVolume`, `Describe*` e permissões do driver CSI.\n- **S3/KMS**: `s3:PutObject/GetObject` e `kms:Decrypt/Encrypt` conforme necessidade; revise *bucket policy* e *key policy*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "4ec33bc04b0c",
    "category": "AWS/EKS",
    "severity": "high",
    "explanation": "Descrição: 'ECR GetAuthorizationToken denied' geralmente indica um problema na categoria AWS/EKS. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Revise *trust policy* do IAM Role (IRSA), políticas do driver CSI e permissões S3/KMS.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Habilite OIDC do cluster (IRSA) e vincule a policy correta à ServiceAccount.",
      "Ajuste permissões IAM com base na ação negada (CloudTrail)."
    ],
    "tags": [
      "ECR",
      "GetAuthorizationToken",
      "denied"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "aws_permissions": [
      "ec2:Describe*",
      "ecr:GetAuthorizationToken",
      "elasticloadbalancing:*",
      "logs:*"
    ],
    "references": []
  },
  {
    "error": "Kubelet create shim task failed",
    "patterns": [
      "failed to create shim task",
      "OCI runtime create failed"
    ],
    "solution": "O problema **Kubelet create shim task failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "e922b5e08e8b",
    "category": "Node/Cluster",
    "severity": "high",
    "explanation": "Descrição: 'Kubelet create shim task failed' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Kubelet",
      "create",
      "failed",
      "shim",
      "task"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Address already in use (container)",
    "patterns": [
      "address already in use",
      "bind: address already in use"
    ],
    "solution": "O problema **Address already in use (container)** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "1c8744debab6",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Address already in use (container)' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Address",
      "already",
      "container",
      "use"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Init container failed",
    "patterns": [
      "Init:CrashLoopBackOff",
      "Init:Error"
    ],
    "solution": "O problema **Init container failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "7d485e3c2059",
    "category": "General",
    "severity": "high",
    "explanation": "Descrição: 'Init container failed' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Init",
      "container",
      "failed"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "StatefulSet PVC pending",
    "patterns": [
      "persistentvolumeclaim .* pending for StatefulSet",
      "pod has unbound immediate PersistentVolumeClaims"
    ],
    "solution": "O problema **StatefulSet PVC pending** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "01b14b533358",
    "category": "Storage/CSI",
    "severity": "medium",
    "explanation": "Descrição: 'StatefulSet PVC pending' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "PVC",
      "StatefulSet",
      "pending"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "HPA external metrics unavailable",
    "patterns": [
      "unable to get external metric",
      "no metrics returned from external metrics API"
    ],
    "solution": "O problema **HPA external metrics unavailable** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "51c6818c694c",
    "category": "Observability",
    "severity": "medium",
    "explanation": "Descrição: 'HPA external metrics unavailable' geralmente indica um problema na categoria Observability. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "HPA",
      "external",
      "metrics",
      "unavailable"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Prometheus rule parse error",
    "patterns": [
      "error loading rules",
      "parsing YAML file .* error"
    ],
    "solution": "O problema **Prometheus rule parse error** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "ce98cb9828b9",
    "category": "Observability",
    "severity": "high",
    "explanation": "Descrição: 'Prometheus rule parse error' geralmente indica um problema na categoria Observability. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Prometheus",
      "error",
      "parse",
      "rule"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Alertmanager 403 or route error",
    "patterns": [
      "unexpected status code 403 from Alertmanager",
      "no route found for path .* in Alertmanager"
    ],
    "solution": "O problema **Alertmanager 403 or route error** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "824d6ff4f67e",
    "category": "Observability",
    "severity": "high",
    "explanation": "Descrição: 'Alertmanager 403 or route error' geralmente indica um problema na categoria Observability. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "403",
      "Alertmanager",
      "error",
      "route"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Istio upstream reset 503",
    "patterns": [
      "503 UF,URX",
      "upstream connect error or disconnect/reset before headers"
    ],
    "solution": "O problema **Istio upstream reset 503** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "4e3e34a43988",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Istio upstream reset 503' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "503",
      "Istio",
      "reset",
      "upstream"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Istio xDS resource not found",
    "patterns": [
      "EDS: no endpoints",
      "RDS: route not found"
    ],
    "solution": "O problema **Istio xDS resource not found** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "536177673a36",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Istio xDS resource not found' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Istio",
      "found",
      "not",
      "resource",
      "xDS"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "NGINX Ingress upstream timed out",
    "patterns": [
      "upstream timed out",
      "110: Connection timed out while reading response header from upstream"
    ],
    "solution": "O problema **NGINX Ingress upstream timed out** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Ingress/Certificados\n- *404 default backend*: `serviceName`/`servicePort` e `pathType` incorretos são comuns.\n- **TLS**: crie `Secret` tipo `kubernetes.io/tls` com `tls.crt`/`tls.key`; cheque *CN/SAN* corretos.\n- Para `x509`/`handshake` erros, valide cadeia de certificados e *trust store* do upstream.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "7b668c590193",
    "category": "Ingress",
    "severity": "medium",
    "explanation": "Descrição: 'NGINX Ingress upstream timed out' geralmente indica um problema na categoria Ingress. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Ajuste `path`, `pathType` e backends; corrija o `Secret` TLS (tipo `kubernetes.io/tls`).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Ingress",
      "NGINX",
      "out",
      "timed",
      "upstream"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "NGINX header too large",
    "patterns": [
      "upstream sent too big header",
      "header size too big"
    ],
    "solution": "O problema **NGINX header too large** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "dfbd8544601e",
    "category": "Ingress",
    "severity": "medium",
    "explanation": "Descrição: 'NGINX header too large' geralmente indica um problema na categoria Ingress. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "NGINX",
      "header",
      "large",
      "too"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "cert-manager DNS-01 propagation failed",
    "patterns": [
      "Waiting for DNS-01 challenge propagation",
      "NXDOMAIN when querying TXT for _acme-challenge"
    ],
    "solution": "O problema **cert-manager DNS-01 propagation failed** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### DNS/CoreDNS\n- Teste dentro do *pod*: `nslookup`/`dig` para o FQDN; cheque `/etc/resolv.conf`.\n- Reinicie `coredns` se travado; confirme *upstream* acessível e políticas de rede liberando DNS.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "40d1c6600888",
    "category": "Networking/DNS",
    "severity": "high",
    "explanation": "Descrição: Falhas de resolução DNS (ex.: 'no such host', 'NXDOMAIN') indicam que o nome não pode ser resolvido pelo CoreDNS ou pelo DNS externo.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl -n kube-system logs deploy/coredns --tail=200",
      "kubectl exec -it <pod> -n <ns> -- nslookup <host>"
    ],
    "fix_steps": [
      "Corrija o FQDN/hostname; confira `coredns` e DNS *upstream*.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Corrija o FQDN/hostname e verifique se há registros A/CNAME/TXT válidos.",
      "Se for serviço K8s, confirme Service/Endpoints e o sufixo .svc.cluster.local.",
      "Cheque políticas de rede/egress e o acesso ao DNS upstream."
    ],
    "tags": [
      "DNS-01",
      "cert-manager",
      "failed",
      "propagation"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl -n kube-system logs deploy/coredns --tail=200",
      "kubectl exec -it <pod> -n <ns> -- nslookup <host>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Leader election lost",
    "patterns": [
      "leaderelection lost",
      "failed to renew lease"
    ],
    "solution": "O problema **Leader election lost** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "b8b8dabb50b9",
    "category": "General",
    "severity": "medium",
    "explanation": "Descrição: 'Leader election lost' geralmente indica um problema na categoria General. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Leader",
      "election",
      "lost"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "DNS not found / NXDOMAIN",
    "patterns": [
      "no such host",
      "Name or service not known",
      "lookup .* on .*: no such host",
      "NXDOMAIN",
      "coredns .* plugin/forward: no upstream host"
    ],
    "solution": "O problema **DNS not found / NXDOMAIN** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### DNS/CoreDNS\n- Teste dentro do *pod*: `nslookup`/`dig` para o FQDN; cheque `/etc/resolv.conf`.\n- Reinicie `coredns` se travado; confirme *upstream* acessível e políticas de rede liberando DNS.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "d567e945fee1",
    "category": "Networking/DNS",
    "severity": "medium",
    "explanation": "Descrição: Falhas de resolução DNS (ex.: 'no such host', 'NXDOMAIN') indicam que o nome não pode ser resolvido pelo CoreDNS ou pelo DNS externo.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl -n kube-system logs deploy/coredns --tail=200",
      "kubectl exec -it <pod> -n <ns> -- nslookup <host>"
    ],
    "fix_steps": [
      "Corrija o FQDN/hostname; confira `coredns` e DNS *upstream*.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Corrija o FQDN/hostname e verifique se há registros A/CNAME/TXT válidos.",
      "Se for serviço K8s, confirme Service/Endpoints e o sufixo .svc.cluster.local.",
      "Cheque políticas de rede/egress e o acesso ao DNS upstream."
    ],
    "tags": [
      "DNS",
      "NXDOMAIN",
      "found",
      "not"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl -n kube-system logs deploy/coredns --tail=200",
      "kubectl exec -it <pod> -n <ns> -- nslookup <host>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "ImagePullBackOff / ErrImagePull",
    "patterns": [
      "Back-off pulling image",
      "ErrImagePull",
      "failed to pull and unpack image",
      "pull access denied"
    ],
    "solution": "O problema **ImagePullBackOff / ErrImagePull** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Falha no *entrypoint*/`command`, dependência externa indisponível, *config* ausente, ou *panic* da aplicação.\n- *Probes* agressivas derrubando o processo durante a inicialização.\n#### Ações imediatas\n- Veja o contêiner anterior: `kubectl logs <pod> -n <ns> --previous` (indica a causa de saída).\n- Descreva o pod e eventos: `kubectl describe pod <pod> -n <ns>` (erros de mount/env/args).\n#### Correções\n- Corrija env/args/arquivos requeridos; torne scripts executáveis (`chmod +x`).\n- Se devido a *readiness/liveness*, relaxe `initialDelaySeconds`, `periodSeconds`, `timeoutSeconds` e `failureThreshold`.\n- Aumente `terminationGracePeriodSeconds` se precisar finalizar com *graceful shutdown*.\n#### Causas comuns\n- Nome/tag inválidos, imagem inexistente, ou credenciais/egresso até o *registry* indisponíveis.\n#### Ações imediatas\n- Confirme *image* e *tag/digest* exatamente como publicadas.\n- Se privado: crie `Secret` tipo `docker-registry` e referencie em `imagePullSecrets`.\n- Teste no nó: `crictl pull <image>:<tag>` (ou `docker/podman`).\n#### Correções\n- Ajuste o nome totalmente qualificado (ex.: `gcr.io/proj/app:1.2.3` / `public.ecr.aws/...`).\n- Garanta permissões no *registry* e políticas de rede/egress liberadas.\n- Use `imagePullPolicy: IfNotPresent` (ou `Always` onde fizer sentido).\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "e06a78c2583f",
    "category": "Image/Registry",
    "severity": "medium",
    "explanation": "Descrição: 'ImagePullBackOff / ErrImagePull' geralmente indica um problema na categoria Image/Registry. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó"
    ],
    "fix_steps": [
      "Corrija `command`/`args`/`entrypoint`; torne scripts executáveis.",
      "Revise *probes* e aumente tempos/thresholds conforme necessidade.",
      "Corrija nome/tag da imagem e *imagePullSecrets*.",
      "Valide conectividade de rede ao *registry* (egresso/HTTP proxy).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Garanta imagePullSecrets corretos e acesso ao registry.",
      "Valide tag/digest e disponibilidade da imagem no registry."
    ],
    "tags": [
      "ErrImagePull",
      "ImagePullBackOff"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl describe pod <pod> -n <ns> | grep -i image",
      "crictl pull <image>:<tag>  # executar no nó",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "OOMKilled (Out Of Memory)",
    "patterns": [
      "OOMKilled",
      "Signal: 9 (OOMKilled)"
    ],
    "solution": "O problema **OOMKilled (Out Of Memory)** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Limite de memória (`resources.limits.memory`) menor que o uso real do processo.\n- *Spikes* de alocação (cache, buffers, *JIT* ou *GC*) não refletidos em `requests`.\n- Vazamentos ou *memory bloat* (por exemplo: grandes *batches*, buffers não liberados).\n#### Ações imediatas\n- Verifique o motivo exato do OOM nos eventos: `kubectl describe pod <pod> -n <ns>` (campo *Last State* / *Reason*).\n- Confira reinícios: `kubectl get pod <pod> -n <ns> -o wide` e `kubectl logs <pod> -n <ns> --previous`.\n- Observe consumo: instale *metrics-server* e rode `kubectl top pod <pod> -n <ns>`.\n- Se JVM: adicione flags que respeitem cgroups (ex.: `-XX:+UseContainerSupport -XX:MaxRAMPercentage=75`);\n  se Node.js: ajuste `--max-old-space-size`; se Python: reduza *workers*/*batch size*.\n#### Correções\n- **Dimensione corretamente**: aumente `requests` para o pico de uso e `limits` com margem (10–30%).\n- **Otimize a aplicação**: reduza paralelismo, *batch size*, *buffers*; corrija vazamentos.\n- **Autoscaling**: considere *Vertical Pod Autoscaler* (VPA) e *HPA* baseado em memória onde aplicável.\n- **Probes**: evite que *liveness* mate o pod durante *warmup* — use `startupProbe` e tempos mais generosos.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "a686fe2a65d8",
    "category": "Pod Runtime",
    "severity": "high",
    "explanation": "Descrição: 'OOMKilled (Out Of Memory)' geralmente indica um problema na categoria Pod Runtime. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl top pod <pod> -n <ns>",
      "kubectl top node"
    ],
    "fix_steps": [
      "Ajuste `resources.requests/limits.memory` baseado no pico observado.",
      "Reduza *batch size*, paralelismo e *caches*; aplique flags de memória do runtime (JVM/Node/Python).",
      "Implemente `startupProbe` para proteger a inicialização e evite *liveness* prematura.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Ajuste requests/limits de CPU/Memória, comandos/args e dependências iniciais.",
      "Cheque volumes/paths/permissions exigidos pelo container."
    ],
    "tags": [
      "Memory",
      "OOMKilled",
      "Out"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl top pod <pod> -n <ns>",
      "kubectl top node",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Pod unschedulable (taints/resources)",
    "patterns": [
      "0/\\d+ nodes are available",
      "insufficient cpu",
      "insufficient memory",
      "node(s) had taint"
    ],
    "solution": "O problema **Pod unschedulable (taints/resources)** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Causas comuns\n- Falta de recursos no cluster, *requests* superestimados, *taints* sem *tolerations*, *affinity/selector* incompatíveis.\n#### Correções\n- Reduza *requests/limits* para *right-sizing* ou **escale** o cluster.\n- Ajuste `nodeSelector`/`nodeAffinity` para rótulos realmente presentes; adicione *tolerations* quando houver *taints*.\n- Revise `topologySpreadConstraints` e *PodDisruptionBudget* que podem bloquear o agendamento.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "68af3ad09e0f",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'Pod unschedulable (taints/resources)' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Reduza *requests* ou escale nós; habilite/ajuste *Cluster Autoscaler*.",
      "Ajuste `nodeSelector`/`affinity`/`tolerations` para casar com os nós disponíveis.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Pod",
      "taints/resources",
      "unschedulable"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "RBAC: Forbidden / Unauthorized",
    "patterns": [
      "Error from server (Forbidden)",
      "User .* cannot .* resource .* in API group .*",
      "Unauthorized"
    ],
    "solution": "O problema **RBAC: Forbidden / Unauthorized** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### RBAC/Autorização\n- Teste permissões: `kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>`.\n- Crie/ajuste `Role`/`ClusterRole` + `RoleBinding`/`ClusterRoleBinding`; garanta `serviceAccountName` correto no *pod*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "f06abf08474c",
    "category": "RBAC/Auth",
    "severity": "high",
    "explanation": "Descrição: 'RBAC: Forbidden / Unauthorized' geralmente indica um problema na categoria RBAC/Auth. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A"
    ],
    "fix_steps": [
      "Crie/ajuste `Role`/`ClusterRole` e *bindings*; valide com `kubectl auth can-i`.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Forbidden",
      "RBAC",
      "Unauthorized"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl auth can-i <verb> <resource> --as=system:serviceaccount:<ns>:<sa>",
      "kubectl get role,rolebinding,clusterrole,clusterrolebinding -A",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "PVC pending / volume not bound",
    "patterns": [
      "pod has unbound immediate PersistentVolumeClaims",
      "persistentvolumeclaim .* pending"
    ],
    "solution": "O problema **PVC pending / volume not bound** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "367f45203bfa",
    "category": "Storage/CSI",
    "severity": "medium",
    "explanation": "Descrição: 'PVC pending / volume not bound' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "PVC",
      "bound",
      "not",
      "pending",
      "volume"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "CSI attach/mount failed (EBS/EFS)",
    "patterns": [
      "AttachVolume.Attach failed",
      "MountVolume.Mount failed",
      "rpc error: code = Internal desc"
    ],
    "solution": "O problema **CSI attach/mount failed (EBS/EFS)** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Diagnóstico de armazenamento\n- Verifique `PVC`/`PV`/`StorageClass`: `kubectl get pvc,pv,sc -A` e `kubectl describe pvc <name> -n <ns>`.\n- Logs do driver CSI (no `kube-system`): `kubectl logs deploy/csi-* -n kube-system --tail=200`.\n#### Correções frequentes\n- Combine `accessModes`/`storageClassName`/zona com o nó onde o *pod* será executado (*node affinity* do volume).\n- Para **Multi-Attach**, use RWX (por ex., EFS/NFS) ou `ReadWriteOncePod` se suportado.\n- Em `MountVolume` falhas: confira *secrets/configmaps* existentes e *subPath* corretos; verifique permissões.\n#### AWS (EKS/IRSA/Storage)\n- **IRSA/STS**: confira *OIDC provider* e *trust policy* do *role*; anote o SA com `eks.amazonaws.com/role-arn`.\n- **EBS/EFS**: políticas IAM para `AttachVolume`, `Describe*` e permissões do driver CSI.\n- **S3/KMS**: `s3:PutObject/GetObject` e `kms:Decrypt/Encrypt` conforme necessidade; revise *bucket policy* e *key policy*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "e07a8091a9fc",
    "category": "Storage/CSI",
    "severity": "high",
    "explanation": "Descrição: 'CSI attach/mount failed (EBS/EFS)' geralmente indica um problema na categoria Storage/CSI. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200"
    ],
    "fix_steps": [
      "Garanta `PVC` em estado `Bound` e `StorageClass` correta.",
      "Para *Multi-Attach*: use RWX (EFS/NFS) ou mude a estratégia para `ReadWriteOncePod`.",
      "Sincronize *zona/zone* do volume com o nó (*volume node affinity*).",
      "Revise *trust policy* do IAM Role (IRSA), políticas do driver CSI e permissões S3/KMS.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Valide StorageClass, provisioner e parâmetros (zona, fsType, iops).",
      "Confirme acesso do Node ao backend (EBS/EFS/NFS) e permissões."
    ],
    "tags": [
      "CSI",
      "EBS/EFS",
      "attach/mount",
      "failed"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get pvc,pv,sc -A",
      "kubectl describe pvc <pvc> -n <ns>",
      "kubectl -n kube-system logs deploy/csi-* --tail=200",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "Node NotReady / kubelet issues",
    "patterns": [
      "NodeNotReady",
      "KubeletNotReady",
      "PLEG is not healthy"
    ],
    "solution": "O problema **Node NotReady / kubelet issues** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### Saúde do nó\n- `NodeNotReady`/`*Pressure`: verifique `kubelet`, uso de disco/FS, inodes e *allocatable resources*.\n- Habilite *eviction thresholds* apropriados e *requests* realistas para evitar *evictions*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "702ba87d4949",
    "category": "Node/Cluster",
    "severity": "medium",
    "explanation": "Descrição: 'Node NotReady / kubelet issues' geralmente indica um problema na categoria Node/Cluster. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>"
    ],
    "fix_steps": [
      "Libere recursos (disco/memória), reponha nós ruins e ajuste *eviction thresholds*.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready."
    ],
    "tags": [
      "Node",
      "NotReady",
      "issues",
      "kubelet"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get nodes -o wide",
      "kubectl describe node <node>",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "references": []
  },
  {
    "error": "STS AssumeRole/IRSA failure",
    "patterns": [
      "InvalidIdentityToken",
      "AccessDenied: Not authorized to perform sts:AssumeRole",
      "could not assume role with web identity"
    ],
    "solution": "O problema **STS AssumeRole/IRSA failure** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### AWS (EKS/IRSA/Storage)\n- **IRSA/STS**: confira *OIDC provider* e *trust policy* do *role*; anote o SA com `eks.amazonaws.com/role-arn`.\n- **EBS/EFS**: políticas IAM para `AttachVolume`, `Describe*` e permissões do driver CSI.\n- **S3/KMS**: `s3:PutObject/GetObject` e `kms:Decrypt/Encrypt` conforme necessidade; revise *bucket policy* e *key policy*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "3fb3dbb81c85",
    "category": "AWS/EKS",
    "severity": "medium",
    "explanation": "Descrição: 'STS AssumeRole/IRSA failure' geralmente indica um problema na categoria AWS/EKS. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Revise *trust policy* do IAM Role (IRSA), políticas do driver CSI e permissões S3/KMS.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Habilite OIDC do cluster (IRSA) e vincule a policy correta à ServiceAccount.",
      "Ajuste permissões IAM com base na ação negada (CloudTrail)."
    ],
    "tags": [
      "AssumeRole/IRSA",
      "STS",
      "failure"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "aws_permissions": [
      "ec2:Describe*",
      "ecr:GetAuthorizationToken",
      "elasticloadbalancing:*",
      "logs:*"
    ],
    "references": []
  },
  {
    "error": "AWS KMS permission / S3 403",
    "patterns": [
      "AccessDeniedException: KMS",
      "403 Forbidden",
      "AccessDenied: Access Denied"
    ],
    "solution": "O problema **AWS KMS permission / S3 403** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### AWS (EKS/IRSA/Storage)\n- **IRSA/STS**: confira *OIDC provider* e *trust policy* do *role*; anote o SA com `eks.amazonaws.com/role-arn`.\n- **EBS/EFS**: políticas IAM para `AttachVolume`, `Describe*` e permissões do driver CSI.\n- **S3/KMS**: `s3:PutObject/GetObject` e `kms:Decrypt/Encrypt` conforme necessidade; revise *bucket policy* e *key policy*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "207caf152b44",
    "category": "AWS/EKS",
    "severity": "medium",
    "explanation": "Descrição: 'AWS KMS permission / S3 403' geralmente indica um problema na categoria AWS/EKS. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Revise *trust policy* do IAM Role (IRSA), políticas do driver CSI e permissões S3/KMS.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Habilite OIDC do cluster (IRSA) e vincule a policy correta à ServiceAccount.",
      "Ajuste permissões IAM com base na ação negada (CloudTrail)."
    ],
    "tags": [
      "403",
      "AWS",
      "KMS",
      "permission"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "aws_permissions": [
      "ec2:Describe*",
      "ecr:GetAuthorizationToken",
      "elasticloadbalancing:*",
      "logs:*"
    ],
    "references": []
  },
  {
    "error": "Route53 record not found / propagation",
    "patterns": [
      "NXDOMAIN when querying",
      "record not found in hosted zone"
    ],
    "solution": "O problema **Route53 record not found / propagation** foi detectado. Abaixo estão causas comuns, diagnóstico prático e correções recomendadas.\n#### AWS (EKS/IRSA/Storage)\n- **IRSA/STS**: confira *OIDC provider* e *trust policy* do *role*; anote o SA com `eks.amazonaws.com/role-arn`.\n- **EBS/EFS**: políticas IAM para `AttachVolume`, `Describe*` e permissões do driver CSI.\n- **S3/KMS**: `s3:PutObject/GetObject` e `kms:Decrypt/Encrypt` conforme necessidade; revise *bucket policy* e *key policy*.\n#### Verificação final\n- Após aplicar correções, **reimplante** e verifique: `kubectl get pods,events -n <ns>` até o *pod* ficar `Ready`.",
    "id": "fa060dfa4e94",
    "category": "AWS/EKS",
    "severity": "medium",
    "explanation": "Descrição: 'Route53 record not found / propagation' geralmente indica um problema na categoria AWS/EKS. Consulte os passos abaixo para confirmar causa-raiz.",
    "diagnostics": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous"
    ],
    "fix_steps": [
      "Revise *trust policy* do IAM Role (IRSA), políticas do driver CSI e permissões S3/KMS.",
      "Reaplique o manifesto e confirme que o *pod* fica `Ready` sem reinícios.",
      "Identifique a causa nos eventos/logs e aplique o ajuste sugerido.",
      "Reimplante o recurso se necessário e confirme que o status mudou para Ready.",
      "Habilite OIDC do cluster (IRSA) e vincule a policy correta à ServiceAccount.",
      "Ajuste permissões IAM com base na ação negada (CloudTrail)."
    ],
    "tags": [
      "Route53",
      "found",
      "not",
      "propagation",
      "record"
    ],
    "k8s_commands": [
      "kubectl get events -A --sort-by=.lastTimestamp",
      "kubectl describe pod <pod> -n <ns>",
      "kubectl logs <pod> -n <ns> --all-containers --tail=300",
      "kubectl logs <pod> -n <ns> --previous",
      "kubectl get deploy,sts,ds -n <ns>",
      "kubectl get pods -n <ns> -o wide",
      "kubectl logs <pod> -n <ns> --all-containers --tail=200"
    ],
    "aws_permissions": [
      "ec2:Describe*",
      "ecr:GetAuthorizationToken",
      "elasticloadbalancing:*",
      "logs:*"
    ],
    "references": []
  }
]